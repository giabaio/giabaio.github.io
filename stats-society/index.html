<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to Bayesian thinking and modelling</title>
    <meta charset="utf-8" />
    <meta name="author" content="Gianluca Baio" />
    <meta name="date" content="2021-10-28" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <script src="libs/freezeframe/freezeframe.min.js"></script>
    <script src="libs/xaringanExtra-freezeframe/freezeframe-init.js"></script>
    <script id="xaringanExtra-freezeframe-options" type="application/json">{"selector":"img[src$=\"gif\"]","trigger":"click","overlay":false,"responsive":true,"warnings":true}</script>
    <!-- (Re)Defines a bunch of LaTeX commands that can then be used directly in the .Rmd file as '\command{...}' -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      TeX: {
        /* This enables color macros */
        extensions: ["color.js"],
        Macros: {
          /* Probability & mathematical symbols */
          Pr: "{\\style{font-family:inherit; font-size: 110%;}{\\text{Pr}}}",
          exp: "{\\style{font-family:inherit; font-size: 105%;}{\\text{exp}}}",
          log: "{\\style{font-family:inherit; font-size: 105%;}{\\text{log}}}",
          ln: "{\\style{font-family:inherit; font-size: 105%;}{\\text{ln}}}",
          logit: "{\\style{font-family:inherit; font-size: 100%;}{\\text{logit}}}",
          HR: "{\\style{font-family:inherit; font-size: 105%;}{\\text{HR}}}",
          OR: "{\\style{font-family:inherit; font-size: 105%;}{\\text{OR}}}",
          E: "{\\style{font-family:inherit; font-size: 105%;}{\\text{E}}}",
          Var: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Var}}}",
          Cov: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Cov}}}",
          Corr: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Corr}}}",
          DIC: "{\\style{font-family:inherit; font-size: 105%;}{\\text{DIC}}}",
          se: "{\\style{font-family:inherit; font-size: 100%;}{\\text{se}}}",
          sd: "{\\style{font-family:inherit; font-size: 100%;}{\\text{sd}}}",
          /* Distributions */
          dnorm: "{\\style{font-family:inherit;}{\\text{Normal}}}",
          dt: "{\\style{font-family:inherit;}{\\text{t}}}",
          ddirch: "{\\style{font-family:inherit;}{\\text{Dirichlet}}}",
          dmulti: "{\\style{font-family:inherit;}{\\text{Multinomial}}}",
          dbeta: "{\\style{font-family:inherit;}{\\text{Beta}}}",
          dgamma: "{\\style{font-family:inherit;}{\\text{Gamma}}}",
          dbern: "{\\style{font-family:inherit;}{\\text{Bernoulli}}}",
          dbin: "{\\style{font-family:inherit;}{\\text{Binomial}}}",
          dpois: "{\\style{font-family:inherit;}{\\text{Poisson}}}",
          dweib: "{\\style{font-family:inherit;}{\\text{Weibull}}}",
          dexp: "{\\style{font-family:inherit;}{\\text{Exponential}}}",
          dlnorm: "{\\style{font-family:inherit;}{\\text{logNormal}}}",
          dunif: "{\\style{font-family:inherit;}{\\text{Uniform}}}",
          /* LaTeX formatting */
          bm: ["{\\boldsymbol #1}",1],
          /* These create macros to typeset numbers in maths with the basic font */
          0: "{\\style{font-family:inherit; font-size: 105%;}{\\text{0}}}",
          1: "{\\style{font-family:inherit; font-size: 105%;}{\\text{1}}}",
          3: "{\\style{font-family:inherit; font-size: 105%;}{\\text{2}}}",
          3: "{\\style{font-family:inherit; font-size: 105%;}{\\text{3}}}",
          4: "{\\style{font-family:inherit; font-size: 105%;}{\\text{4}}}",
          5: "{\\style{font-family:inherit; font-size: 105%;}{\\text{5}}}",
          6: "{\\style{font-family:inherit; font-size: 105%;}{\\text{6}}}",
          7: "{\\style{font-family:inherit; font-size: 105%;}{\\text{7}}}",
          8: "{\\style{font-family:inherit; font-size: 105%;}{\\text{8}}}",
          9: "{\\style{font-family:inherit; font-size: 105%;}{\\text{9}}}",
          /* Health economics quantities */
          icer: "{\\style{font-family:inherit; font-size: 100%;}{\\text{ICER}}}",
          nb: "{\\style{font-family:inherit; font-size: 100%;}{\\text{NB}}}",
          ol: "{\\style{font-family:inherit; font-size: 100%;}{\\text{OL}}}",
          ceac: "{\\style{font-family:inherit; font-size: 100%;}{\\text{CEAC}}}",
          evpi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVPI}}}",
          evppi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVPPI}}}",
          evsi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVSI}}}"
        }
      }
    });
    </script>
    <link rel="stylesheet" href="assets/ucl-powerpoint.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




class: title-slide

# Introduction to Bayesian thinking and modelling

## Gianluca Baio

### [Department of Statistical Science](https://www.ucl.ac.uk/statistics/) | University College London    

.title-small[
&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="position:relative;display:inline-block;top:.1em;fill:#00acee;height:0.8em;"&gt;  [ comment ]  &lt;path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"&gt;&lt;/path&gt;&lt;/svg&gt;  [g.baio@ucl.ac.uk](mailto:g.baio@ucl.ac.uk)
&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="position:relative;display:inline-block;top:.1em;fill:#EA7600;height:0.8em;"&gt;  [ comment ]  &lt;path d="M503.52,241.48c-.12-1.56-.24-3.12-.24-4.68v-.12l-.36-4.68v-.12a245.86,245.86,0,0,0-7.32-41.15c0-.12,0-.12-.12-.24l-1.08-4c-.12-.24-.12-.48-.24-.6-.36-1.2-.72-2.52-1.08-3.72-.12-.24-.12-.6-.24-.84-.36-1.2-.72-2.4-1.08-3.48-.12-.36-.24-.6-.36-1-.36-1.2-.72-2.28-1.2-3.48l-.36-1.08c-.36-1.08-.84-2.28-1.2-3.36a8.27,8.27,0,0,0-.36-1c-.48-1.08-.84-2.28-1.32-3.36-.12-.24-.24-.6-.36-.84-.48-1.2-1-2.28-1.44-3.48,0-.12-.12-.24-.12-.36-1.56-3.84-3.24-7.68-5-11.4l-.36-.72c-.48-1-.84-1.8-1.32-2.64-.24-.48-.48-1.08-.72-1.56-.36-.84-.84-1.56-1.2-2.4-.36-.6-.6-1.2-1-1.8s-.84-1.44-1.2-2.28c-.36-.6-.72-1.32-1.08-1.92s-.84-1.44-1.2-2.16a18.07,18.07,0,0,0-1.2-2c-.36-.72-.84-1.32-1.2-2s-.84-1.32-1.2-2-.84-1.32-1.2-1.92-.84-1.44-1.32-2.16a15.63,15.63,0,0,0-1.2-1.8L463.2,119a15.63,15.63,0,0,0-1.2-1.8c-.48-.72-1.08-1.56-1.56-2.28-.36-.48-.72-1.08-1.08-1.56l-1.8-2.52c-.36-.48-.6-.84-1-1.32-1-1.32-1.8-2.52-2.76-3.72a248.76,248.76,0,0,0-23.51-26.64A186.82,186.82,0,0,0,412,62.46c-4-3.48-8.16-6.72-12.48-9.84a162.49,162.49,0,0,0-24.6-15.12c-2.4-1.32-4.8-2.52-7.2-3.72a254,254,0,0,0-55.43-19.56c-1.92-.36-3.84-.84-5.64-1.2h-.12c-1-.12-1.8-.36-2.76-.48a236.35,236.35,0,0,0-38-4H255.14a234.62,234.62,0,0,0-45.48,5c-33.59,7.08-63.23,21.24-82.91,39-1.08,1-1.92,1.68-2.4,2.16l-.48.48H124l-.12.12.12-.12a.12.12,0,0,0,.12-.12l-.12.12a.42.42,0,0,1,.24-.12c14.64-8.76,34.92-16,49.44-19.56l5.88-1.44c.36-.12.84-.12,1.2-.24,1.68-.36,3.36-.72,5.16-1.08.24,0,.6-.12.84-.12C250.94,20.94,319.34,40.14,367,85.61a171.49,171.49,0,0,1,26.88,32.76c30.36,49.2,27.48,111.11,3.84,147.59-34.44,53-111.35,71.27-159,24.84a84.19,84.19,0,0,1-25.56-59,74.05,74.05,0,0,1,6.24-31c1.68-3.84,13.08-25.67,18.24-24.59-13.08-2.76-37.55,2.64-54.71,28.19-15.36,22.92-14.52,58.2-5,83.28a132.85,132.85,0,0,1-12.12-39.24c-12.24-82.55,43.31-153,94.31-170.51-27.48-24-96.47-22.31-147.71,15.36-29.88,22-51.23,53.16-62.51,90.36,1.68-20.88,9.6-52.08,25.8-83.88-17.16,8.88-39,37-49.8,62.88-15.6,37.43-21,82.19-16.08,124.79.36,3.24.72,6.36,1.08,9.6,19.92,117.11,122,206.38,244.78,206.38C392.77,503.42,504,392.19,504,255,503.88,250.48,503.76,245.92,503.52,241.48Z"&gt;&lt;/path&gt;&lt;/svg&gt;  [http://www.statistica.it/gianluca/](http://www.statistica.it/gianluca/)
&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="position:relative;display:inline-block;top:.1em;fill:#EA7600;height:0.8em;"&gt;  [ comment ]  &lt;path d="M503.52,241.48c-.12-1.56-.24-3.12-.24-4.68v-.12l-.36-4.68v-.12a245.86,245.86,0,0,0-7.32-41.15c0-.12,0-.12-.12-.24l-1.08-4c-.12-.24-.12-.48-.24-.6-.36-1.2-.72-2.52-1.08-3.72-.12-.24-.12-.6-.24-.84-.36-1.2-.72-2.4-1.08-3.48-.12-.36-.24-.6-.36-1-.36-1.2-.72-2.28-1.2-3.48l-.36-1.08c-.36-1.08-.84-2.28-1.2-3.36a8.27,8.27,0,0,0-.36-1c-.48-1.08-.84-2.28-1.32-3.36-.12-.24-.24-.6-.36-.84-.48-1.2-1-2.28-1.44-3.48,0-.12-.12-.24-.12-.36-1.56-3.84-3.24-7.68-5-11.4l-.36-.72c-.48-1-.84-1.8-1.32-2.64-.24-.48-.48-1.08-.72-1.56-.36-.84-.84-1.56-1.2-2.4-.36-.6-.6-1.2-1-1.8s-.84-1.44-1.2-2.28c-.36-.6-.72-1.32-1.08-1.92s-.84-1.44-1.2-2.16a18.07,18.07,0,0,0-1.2-2c-.36-.72-.84-1.32-1.2-2s-.84-1.32-1.2-2-.84-1.32-1.2-1.92-.84-1.44-1.32-2.16a15.63,15.63,0,0,0-1.2-1.8L463.2,119a15.63,15.63,0,0,0-1.2-1.8c-.48-.72-1.08-1.56-1.56-2.28-.36-.48-.72-1.08-1.08-1.56l-1.8-2.52c-.36-.48-.6-.84-1-1.32-1-1.32-1.8-2.52-2.76-3.72a248.76,248.76,0,0,0-23.51-26.64A186.82,186.82,0,0,0,412,62.46c-4-3.48-8.16-6.72-12.48-9.84a162.49,162.49,0,0,0-24.6-15.12c-2.4-1.32-4.8-2.52-7.2-3.72a254,254,0,0,0-55.43-19.56c-1.92-.36-3.84-.84-5.64-1.2h-.12c-1-.12-1.8-.36-2.76-.48a236.35,236.35,0,0,0-38-4H255.14a234.62,234.62,0,0,0-45.48,5c-33.59,7.08-63.23,21.24-82.91,39-1.08,1-1.92,1.68-2.4,2.16l-.48.48H124l-.12.12.12-.12a.12.12,0,0,0,.12-.12l-.12.12a.42.42,0,0,1,.24-.12c14.64-8.76,34.92-16,49.44-19.56l5.88-1.44c.36-.12.84-.12,1.2-.24,1.68-.36,3.36-.72,5.16-1.08.24,0,.6-.12.84-.12C250.94,20.94,319.34,40.14,367,85.61a171.49,171.49,0,0,1,26.88,32.76c30.36,49.2,27.48,111.11,3.84,147.59-34.44,53-111.35,71.27-159,24.84a84.19,84.19,0,0,1-25.56-59,74.05,74.05,0,0,1,6.24-31c1.68-3.84,13.08-25.67,18.24-24.59-13.08-2.76-37.55,2.64-54.71,28.19-15.36,22.92-14.52,58.2-5,83.28a132.85,132.85,0,0,1-12.12-39.24c-12.24-82.55,43.31-153,94.31-170.51-27.48-24-96.47-22.31-147.71,15.36-29.88,22-51.23,53.16-62.51,90.36,1.68-20.88,9.6-52.08,25.8-83.88-17.16,8.88-39,37-49.8,62.88-15.6,37.43-21,82.19-16.08,124.79.36,3.24.72,6.36,1.08,9.6,19.92,117.11,122,206.38,244.78,206.38C392.77,503.42,504,392.19,504,255,503.88,250.48,503.76,245.92,503.52,241.48Z"&gt;&lt;/path&gt;&lt;/svg&gt;  [https://egon.stats.ucl.ac.uk/research/statistics-health-economics/](https://egon.stats.ucl.ac.uk/research/statistics-health-economics/)
&lt;svg viewBox="0 0 496 512" xmlns="http://www.w3.org/2000/svg" style="position:relative;display:inline-block;top:.1em;fill:black;height:0.8em;"&gt;  [ comment ]  &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;&lt;/svg&gt;  [https://github.com/giabaio](https://github.com/giabaio)
&lt;svg viewBox="0 0 496 512" xmlns="http://www.w3.org/2000/svg" style="position:relative;display:inline-block;top:.1em;fill:black;height:0.8em;"&gt;  [ comment ]  &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;&lt;/svg&gt;  [https://github.com/StatisticsHealthEconomics](https://github.com/StatisticsHealthEconomics)
&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="position:relative;display:inline-block;top:.1em;fill:#00acee;height:0.8em;"&gt;  [ comment ]  &lt;path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"&gt;&lt;/path&gt;&lt;/svg&gt;  [@gianlubaio](https://twitter.com/gianlubaio)     
]

### Know your Professor, UCL Statistical Society 
&lt;!-- Can also separate the various components of the extra argument 'params', eg as in 
### Know your Professor, UCL Statistical Society, KYP &amp;ndash; UCL Stats Society
--&gt;

28 October 2021

&lt;!-- This adds a footer (optional and with other possibilities...) --&gt;
.footer-left[
&lt;span&gt;&lt;a href="http://www.statistica.it/gianluca/"&gt;&lt;img src="assets/logo.png" title="Go home" width="2.0%"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span style="position: relative; bottom: 7px; color: #D5D5D5;"&gt; &amp;nbsp; &amp;copy; Gianluca Baio (UCL)&lt;/span&gt;
]

---

layout: true
.footer-left[
&lt;span&gt;&lt;a href="http://www.statistica.it/gianluca/"&gt;&lt;img src="assets/logo.png" title="Go home" width="2.0%"&gt;&lt;/a&gt;&lt;/span&gt; &lt;span style="position: relative; bottom: 7px; color: #D5D5D5;"&gt; &amp;nbsp; &amp;copy; Gianluca Baio (UCL)&lt;/span&gt;
]
&lt;!-- Can also include social media icons &amp; hyperlinks --&gt;
.footer-social[
&amp;nbsp;&lt;a href="https://twitter.com/giabaio"; title="Follow me on Twitter"&gt;&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="position:relative;display:inline-block;top:.1em;fill:#bcc0c4;height:0.8em;bottom:1em;"&gt;
  [ comment ]
  &lt;path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="mailto:g.baio@ucl.ac.uk"; title="Email me"&gt;&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="position:relative;display:inline-block;top:.1em;fill:#bcc0c4;height:0.8em;"&gt;
  [ comment ]
  &lt;path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="http://www.statistica.it/gianluca"; title="Visit my website"&gt;&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="position:relative;display:inline-block;top:.1em;fill:#bcc0c4;height:0.8em;"&gt;
  [ comment ]
  &lt;path d="M503.52,241.48c-.12-1.56-.24-3.12-.24-4.68v-.12l-.36-4.68v-.12a245.86,245.86,0,0,0-7.32-41.15c0-.12,0-.12-.12-.24l-1.08-4c-.12-.24-.12-.48-.24-.6-.36-1.2-.72-2.52-1.08-3.72-.12-.24-.12-.6-.24-.84-.36-1.2-.72-2.4-1.08-3.48-.12-.36-.24-.6-.36-1-.36-1.2-.72-2.28-1.2-3.48l-.36-1.08c-.36-1.08-.84-2.28-1.2-3.36a8.27,8.27,0,0,0-.36-1c-.48-1.08-.84-2.28-1.32-3.36-.12-.24-.24-.6-.36-.84-.48-1.2-1-2.28-1.44-3.48,0-.12-.12-.24-.12-.36-1.56-3.84-3.24-7.68-5-11.4l-.36-.72c-.48-1-.84-1.8-1.32-2.64-.24-.48-.48-1.08-.72-1.56-.36-.84-.84-1.56-1.2-2.4-.36-.6-.6-1.2-1-1.8s-.84-1.44-1.2-2.28c-.36-.6-.72-1.32-1.08-1.92s-.84-1.44-1.2-2.16a18.07,18.07,0,0,0-1.2-2c-.36-.72-.84-1.32-1.2-2s-.84-1.32-1.2-2-.84-1.32-1.2-1.92-.84-1.44-1.32-2.16a15.63,15.63,0,0,0-1.2-1.8L463.2,119a15.63,15.63,0,0,0-1.2-1.8c-.48-.72-1.08-1.56-1.56-2.28-.36-.48-.72-1.08-1.08-1.56l-1.8-2.52c-.36-.48-.6-.84-1-1.32-1-1.32-1.8-2.52-2.76-3.72a248.76,248.76,0,0,0-23.51-26.64A186.82,186.82,0,0,0,412,62.46c-4-3.48-8.16-6.72-12.48-9.84a162.49,162.49,0,0,0-24.6-15.12c-2.4-1.32-4.8-2.52-7.2-3.72a254,254,0,0,0-55.43-19.56c-1.92-.36-3.84-.84-5.64-1.2h-.12c-1-.12-1.8-.36-2.76-.48a236.35,236.35,0,0,0-38-4H255.14a234.62,234.62,0,0,0-45.48,5c-33.59,7.08-63.23,21.24-82.91,39-1.08,1-1.92,1.68-2.4,2.16l-.48.48H124l-.12.12.12-.12a.12.12,0,0,0,.12-.12l-.12.12a.42.42,0,0,1,.24-.12c14.64-8.76,34.92-16,49.44-19.56l5.88-1.44c.36-.12.84-.12,1.2-.24,1.68-.36,3.36-.72,5.16-1.08.24,0,.6-.12.84-.12C250.94,20.94,319.34,40.14,367,85.61a171.49,171.49,0,0,1,26.88,32.76c30.36,49.2,27.48,111.11,3.84,147.59-34.44,53-111.35,71.27-159,24.84a84.19,84.19,0,0,1-25.56-59,74.05,74.05,0,0,1,6.24-31c1.68-3.84,13.08-25.67,18.24-24.59-13.08-2.76-37.55,2.64-54.71,28.19-15.36,22.92-14.52,58.2-5,83.28a132.85,132.85,0,0,1-12.12-39.24c-12.24-82.55,43.31-153,94.31-170.51-27.48-24-96.47-22.31-147.71,15.36-29.88,22-51.23,53.16-62.51,90.36,1.68-20.88,9.6-52.08,25.8-83.88-17.16,8.88-39,37-49.8,62.88-15.6,37.43-21,82.19-16.08,124.79.36,3.24.72,6.36,1.08,9.6,19.92,117.11,122,206.38,244.78,206.38C392.77,503.42,504,392.19,504,255,503.88,250.48,503.76,245.92,503.52,241.48Z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp;
]

&lt;!-- Can also add a center footer, eg to include the title of the talk --&gt;
.footer-center[
KYP &amp;ndash; UCL Stats Society
]
&lt;!-- And a right footer, to include the date --&gt;
.footer-right[
Know your Professor, 28 Oct 2021
]

---

# Disclaimer...

&lt;center&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p lang="en" dir="ltr"&gt;Best opening sentence &lt;a href="https://twitter.com/hashtag/ISPOREurope?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#ISPOREurope&lt;/a&gt; from Gianluca Baio: “statisticians should rule the world and Bayesian statisticians should rule all statisticians” &lt;a href="https://t.co/GN2w7liAcR"&gt;https://t.co/GN2w7liAcR&lt;/a&gt;&lt;/p&gt;&amp;mdash; Manuela Joore (@ManuelaJoore) &lt;a href="https://twitter.com/ManuelaJoore/status/1191397718930939904?ref_src=twsrc%5Etfw"&gt;November 4, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt; 
&lt;/center&gt;

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;
...Just so you know what you're about to get into... 😉

---

# Summary 

- Sampling variability
   - Probability calculus vs Statistics

- Deductive inference
   - "Standard" statistical methods
   - Confidence intervals &amp; testing
   
- Inductive inference
   - Bayesian reasoning
   - Basic ideas
   - Forming "priors"

- Some examples
---


# What is statistics all about?

- Typically, we observe some data and we want to use them to learn about some unobservable feature of the general population in which we are interested

- To do this, we use statistical models to describe the probabilistic mechanism by which (**we assume!**) that the data have arisen

&lt;center&gt;
&lt;center&gt;&lt;img src=./img/what-is-stats1.png width='100%' title=''&gt;&lt;/center&gt;
&lt;/center&gt;

**NB**: Roman letters `\((y\)` or `\(x)\)` typically indicate **observable data**, while Greek letters `\((\theta\)`, `\(\mu\)`, `\(\sigma\)`, `\(\ldots)\)` indicate **population parameters**

---

# Sampling variability .subtitle[Probability calculus]

&lt;center&gt;&lt;img src=./img/prob_calculus.png width='80%' title='Probability calculus is a process whereby we assume a known data generating process and we assess/propagate the sampling variability, e.g. the ways in which data can arise. From the entire population, we may enumerate all the possible ways of obtaining samples of a specific size'&gt;&lt;/center&gt;

---

# Sampling variability .subtitle[Statistics]

&lt;center&gt;&lt;img src=./img/statistics.png width='80%' title='Statistics is essentially the inverse problem - we only have one observed dataset and based on the observations and some assumptions about the underlying data generating process, we want to infer some features of the parameters that characterise the underlying variability'&gt;&lt;/center&gt;

In reality we observe **only one** such sample (out of the many possible &amp;ndash; in fact there are **252** different ways of picking **at random** 5 units out of a population of size 10!) and we want to use the information contained in **that** sample to **infer** about the population parameters (e.g. the true mean and standard deviation)

---

background-image: url("img/Sherlock.png")
background-size: cover

# .black[The Sherlock .alignright[conundrum]]

---

# **Deductive** vs inductive inference

&lt;center&gt;&lt;img src=./img/deduction1.png width='85%' title='Imagine a data generating process, where there are three possible 'true' values for the main parameter (the effect difference Delta). Then there are many possible outcomes, say an observed difference of -5%, 0%, 5%, 10% or 15%'&gt;&lt;/center&gt;

---

count: false
# **Deductive** vs inductive inference

&lt;center&gt;&lt;img src=./img/deduction2.png width='85%' title='In a frequentist set up, you fix the value of the model parameters and then make a probabilistic calculation on how likely the observed data are under the alleged data generation process. Then you can compare that probabilistic calculation with similar ones for other possible observed data (which in fact have not been observed!)'&gt;&lt;/center&gt;

&lt;span style="display:block; margin-top: 2em ;"&gt;&lt;/span&gt;

- Standard (frequentist) procedures fix the working hypotheses and, **by deduction**, make inference on the observed data:
   - If my hypothesis is true, what is the probability of randomly selecting the data that I actually observed? If small, then *deduce* weak support of the evidence to the hypothesis
--

   - Assess `\(\Pr(\class{blue}{\style{font-family:inherit;}{\text{Observed data}}} \mid \class{orange}{\style{font-family:inherit;}{\text{Hypothesis}}})\)`
   - Directly relevant for standard frequentist summaries, eg p-values, Confidence Intervals, etc
   - **NB**: Comparison with data that could have been observed, but haven't!

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
.alignright[
.small[Adapted from &lt;svg viewBox="0 0 384 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  &lt;g label="icon" id="layer6" groupmode="layer"&gt;    &lt;path id="path2" d="M 120.19265,177.73779 C 123.18778,77.35076 64.277527,63.999998 64.277527,63.999998 v 31.26245 C 40.834519,83.611374 18.32863,81.929634 18.32863,81.929634 V 337.10903 c 0,0 98.10414,-11.41744 98.10414,84.40952 0,0 36.58424,-153.37442 248.86103,26.48145 0,-61.59342 0.37757,-216.93925 0.37757,-268.28471 C 169.9561,37.131382 120.1931,177.73779 120.1931,177.73779 Z m 187.20631,173.82056 -12.37599,-97.65441 h -0.448 l -40.72819,97.65441 h -17.55994 l -38.9362,-97.65441 h -0.448 l -14.17589,97.65441 h -43.87514 l 28.8015,-169.61925 h 43.42716 l 34.43518,90.6496 36.46566,-90.6496 h 43.87513 l 25.6817,169.61925 h -44.13938 z" style="stroke-width:0.0675239"&gt;&lt;/path&gt;  &lt;/g&gt;&lt;/svg&gt; [Goodman (1999)](https://pubmed.ncbi.nlm.nih.gov/10383371/)]
]
---

# Confidence intervals

### &lt;svg viewBox="0 0 576 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;position:relative;display:inline-block;top:.1em;fill:red;"&gt;  [ comment ]  &lt;path d="M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z"&gt;&lt;/path&gt;&lt;/svg&gt; See [http://www.statistica.it/gianluca/teaching/intro-stats/interval-estimation.html](http://www.statistica.it/gianluca/teaching/intro-stats/interval-estimation.html)!

Drug to cure headaches - "true" probability of success: `\(\pi = 40/73 \approx 0.55\)`

---

count: false
# Confidence intervals

### &lt;svg viewBox="0 0 576 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;position:relative;display:inline-block;top:.1em;fill:red;"&gt;  [ comment ]  &lt;path d="M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z"&gt;&lt;/path&gt;&lt;/svg&gt; See [http://www.statistica.it/gianluca/teaching/intro-stats/interval-estimation.html](http://www.statistica.it/gianluca/teaching/intro-stats/interval-estimation.html)!

.lightgray[Drug to cure headaches - "true" probability of success:] `\(\class{lightgray}{\pi = 40/73 \approx 0.55}\)`

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

- You get to see data for, say, `\(n=10\)` individuals, under the "true" **data generating process** (DGP): `\(\boldsymbol{y}=(y_1,\ldots,y_{10})=(0,0,1,1,0,1,0,1,0,1)\)`

-  Can make estimates to infer from sample to population
   - Sample mean: `\(\displaystyle \bar{y} = \hat\pi = \sum_{i=1}^{n} \frac{y_i}{n} = \frac{5}{10} = 0.5 \quad\)` Standard error: `\(\displaystyle \se(\hat\pi) = \sqrt{\frac{\hat\pi(1-\hat\pi)}{n}}=0.16\)`

--


- Can compute the interval estimate (using some approximation/theoretical results...)
$$\style{font-family:inherit;}{\text{95% CI}} \approx \left[ \hat\pi-2\se(\hat\pi);\, \hat\pi+2\se(\hat\pi) \right] = \left[ 0.5-0.32; 0.5+0.32 \right] = \left[0.19; 0.81  \right] $$

- Assuming the observed sample is representative of the DGP and using the sample estimates, **if** we were able to replicate the experiment over and over again under the same conditions, 95% of the times, the estimate for the "true" probability of success will be included in the interval `\(\left[0.19;0.81 \right]\)`

- **That** is how you interpret a 95% Confidence Interval!

---

count: false
# Confidence intervals

- Simulate `\(n_{sim}\)` (e.g. `\(=20\)`) studies sampling data from a DGP assuming a "true" `\(\pi=0.5\)` (although in fact, `\(\pi=0.55\)`!) and `\(n=10\)`    
- For each, estimate the probability `\(\hat\pi\)`

&lt;center&gt;&lt;img src=./img/CIs.png width='45%' title='A simulation experiment that shows that 1 in 20 simulated outcomes from the assumed data generating process would not be 'covered' by the interval estimation procedure'&gt;&lt;/center&gt;

---

count: false
# Confidence intervals

&lt;center&gt;
&lt;iframe width="600" height="400" src="https://www.youtube.com/embed/pjvQFtlNQ-M" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/center&gt;

---

# Sample size calculations

&lt;center&gt;
&lt;iframe width="600" height="400" src="https://www.youtube.com/embed/PbODigCZqL8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/center&gt;

---

# Sample size calculations

## Designing a study

- Designing a study is just as important as analysing it
   - If we don't have "enough" information in the data, we won't be able to detect an underlying signal

- Related to "hypothesis" testing

&lt;center&gt;&lt;img src=./img/tab_H0.png width='700px' title=''&gt;&lt;/center&gt;

1. Set the Type I error to some low level (**typically**: `\(\alpha=0.05\)`)
2. Set the Type II error to some set level (**typically**: `\(\beta=0.10\)` or `\(\beta=0.20\)`)
3. Define the "clinically relevant outcome" (eg difference in treatment effects), `\(\delta\)`
4. Set an estimate of variability in the underlying population
5. Use assumptions about sampling variability and determine minimum number of observations to be able to detect `\(\delta\)`

Originally devised to guide quality control of processes

---

# I need a pee(-value)...

## Analysing a study

- Interpretation: Under the null hypothesis (ie **IF** it is true), what is the probability of
observing something as extreme or even more extreme as the observed data?


&lt;span style="display:block; margin-top: 4rem ;"&gt;&lt;/span&gt;
.pull-left[
&lt;img src="./img/unnamed-chunk-2-1.png" style="display: block; margin: auto;" width="160%" title="The p-value can be interpreted as the area under the assumed data generating process, described by the sampling distibution, under which a result 'as extreme or even more extreme than the one we have actually observed' obtains"&gt;
] 
.pull-right[
- If `\(p &lt; 0.01\)` then **strong** evidence against the null hypothesis

- If `\(0.01 &lt; p &lt; 0.05\)` then **fairly strong** evidence against the null hypothesis

- If `\(p &gt; 0.05\)` then **little or no evidence** against the null hypothesis

&lt;center&gt;&lt;img src=./img/peevalue.jpg width='100px' title=''&gt;&lt;/center&gt;
]

---

# Two sides of the same coin?

- Often, hypothesis testing and p-values are seen as the same thing. .red[**They are not!**]

--

- .olive[**Hypothesis testing**] (HT)    
   - Considers formally two competing hypotheses &amp;ndash; a "null" and an "alternative" (**NB**: that determines the treatment effect)   
   - .olive[**Sets**] the probabilities of error `\(\alpha\)` and `\(\beta\)`   
   - Aims at "rejecting" the null &amp;ndash; so it has a binary outcome (yes/no)

- .orange[**Significance testing**] (ST, p-values)    
   - Concerned with the sampling distribution of the data under the null hypothesis    
   - Measures the strength of the evidence for/against the null, but has no formal involvement of alternative explanations for the observed data

--

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
- `\(p \neq \alpha\)` even if often the **threshold** is set at 0.05 for both!    
  - `\(\alpha\)` is .olive[**set**] by the researcher   
  - `\(p\)` is .orange[**computed**] from the data (as extreme or more extreme than those observed)

--


- **NB**: Confusingly, experimental studies are .olive[designed] under a HT setting, but .orange[analysed] under a ST setting!

- Increasing recognition of pitfalls in science ([here](http://annals.org/aim/fullarticle/712762/toward-evidence-based-medical-statistics-1-p-value-fallacy) and [here](https://www.amstat.org/asa/files/pdfs/P-ValueStatement.pdf))    

---

# Is there another way?...

&lt;center&gt;&lt;img src=./img/brexit_bridge.jpg width='65%' title=''&gt;&lt;/center&gt;

---

# Deductive vs **inductive** inference

&lt;center&gt;&lt;img src=./img/induction1.png width='85%' title='An inductive process still considers the same data generating process representation, with possible values of the model parameters and possible realisations of the observable data'&gt;&lt;/center&gt;

&lt;span style="display:block; margin-top: 2em ;"&gt;&lt;/span&gt;

- The **Bayesian** philosophy proceeds fixing the value of the observed data and, **by induction**, makes inference on unobservable hypotheses
   - What is the probability of my hypothesis, given the data I observed? If less than the probability of other competing hypotheses, then weak support of the evidence to the hypothesis
   
---

count: false
# Deductive vs **inductive** inference

&lt;center&gt;&lt;img src=./img/induction2.png width='85%' title='The difference is that instead of fixing the value of the unobservable model parameters, a Bayesian (inductive) process, considers as fixed the observed data (because once they have been observed there is no more uncertainty about their actual value). The model parameters are subject to uncertainty and then you make a probabilistic assessment about them, given the observed data'&gt;&lt;/center&gt;

&lt;span style="display:block; margin-top: 2em ;"&gt;&lt;/span&gt;

- The **Bayesian** philosophy proceeds fixing the value of the observed data and, **by induction**, makes inference on unobservable hypotheses
   - What is the probability of my hypothesis, given the data I observed? If less than the probability of other competing hypotheses, then weak support of the evidence to the hypothesis
   - Assess `\(\Pr(\color{#ff8811}{\style{font-family:inherit;}{\text{Hypothesis}}} \mid \color{#0000FF}{\style{font-family:inherit;}{\text{Observed data}}})\)`
   - Can express in terms of an **interval** estimate: `\(\Pr(a \leq \style{font-family:inherit;}{\text{parameter}} \leq b \mid \style{font-family:inherit;}{\text{Data}})\)`
   - **NB**: Unobserved data have no role in the inference!

---


# Bayesian inference 

## How did it all start?

In 1763, Reverend Thomas Bayes of Tunbridge Wells wrote

&lt;center&gt;&lt;img src=./img/bayes-quote.jpg width='650px' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;

In modern language, given `\(r \sim \style{font-family:inherit;}{\text{Binomial}}(\theta,n)\)`, what is
`\(\Pr( \theta_1 &lt; \theta &lt; \theta_2\mid r,n)\)`?

&lt;span style="display:block; margin-top: 3rem ;"&gt;&lt;/span&gt;

.content-box-beamer[

### Some historical references

&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M503.52,241.48c-.12-1.56-.24-3.12-.24-4.68v-.12l-.36-4.68v-.12a245.86,245.86,0,0,0-7.32-41.15c0-.12,0-.12-.12-.24l-1.08-4c-.12-.24-.12-.48-.24-.6-.36-1.2-.72-2.52-1.08-3.72-.12-.24-.12-.6-.24-.84-.36-1.2-.72-2.4-1.08-3.48-.12-.36-.24-.6-.36-1-.36-1.2-.72-2.28-1.2-3.48l-.36-1.08c-.36-1.08-.84-2.28-1.2-3.36a8.27,8.27,0,0,0-.36-1c-.48-1.08-.84-2.28-1.32-3.36-.12-.24-.24-.6-.36-.84-.48-1.2-1-2.28-1.44-3.48,0-.12-.12-.24-.12-.36-1.56-3.84-3.24-7.68-5-11.4l-.36-.72c-.48-1-.84-1.8-1.32-2.64-.24-.48-.48-1.08-.72-1.56-.36-.84-.84-1.56-1.2-2.4-.36-.6-.6-1.2-1-1.8s-.84-1.44-1.2-2.28c-.36-.6-.72-1.32-1.08-1.92s-.84-1.44-1.2-2.16a18.07,18.07,0,0,0-1.2-2c-.36-.72-.84-1.32-1.2-2s-.84-1.32-1.2-2-.84-1.32-1.2-1.92-.84-1.44-1.32-2.16a15.63,15.63,0,0,0-1.2-1.8L463.2,119a15.63,15.63,0,0,0-1.2-1.8c-.48-.72-1.08-1.56-1.56-2.28-.36-.48-.72-1.08-1.08-1.56l-1.8-2.52c-.36-.48-.6-.84-1-1.32-1-1.32-1.8-2.52-2.76-3.72a248.76,248.76,0,0,0-23.51-26.64A186.82,186.82,0,0,0,412,62.46c-4-3.48-8.16-6.72-12.48-9.84a162.49,162.49,0,0,0-24.6-15.12c-2.4-1.32-4.8-2.52-7.2-3.72a254,254,0,0,0-55.43-19.56c-1.92-.36-3.84-.84-5.64-1.2h-.12c-1-.12-1.8-.36-2.76-.48a236.35,236.35,0,0,0-38-4H255.14a234.62,234.62,0,0,0-45.48,5c-33.59,7.08-63.23,21.24-82.91,39-1.08,1-1.92,1.68-2.4,2.16l-.48.48H124l-.12.12.12-.12a.12.12,0,0,0,.12-.12l-.12.12a.42.42,0,0,1,.24-.12c14.64-8.76,34.92-16,49.44-19.56l5.88-1.44c.36-.12.84-.12,1.2-.24,1.68-.36,3.36-.72,5.16-1.08.24,0,.6-.12.84-.12C250.94,20.94,319.34,40.14,367,85.61a171.49,171.49,0,0,1,26.88,32.76c30.36,49.2,27.48,111.11,3.84,147.59-34.44,53-111.35,71.27-159,24.84a84.19,84.19,0,0,1-25.56-59,74.05,74.05,0,0,1,6.24-31c1.68-3.84,13.08-25.67,18.24-24.59-13.08-2.76-37.55,2.64-54.71,28.19-15.36,22.92-14.52,58.2-5,83.28a132.85,132.85,0,0,1-12.12-39.24c-12.24-82.55,43.31-153,94.31-170.51-27.48-24-96.47-22.31-147.71,15.36-29.88,22-51.23,53.16-62.51,90.36,1.68-20.88,9.6-52.08,25.8-83.88-17.16,8.88-39,37-49.8,62.88-15.6,37.43-21,82.19-16.08,124.79.36,3.24.72,6.36,1.08,9.6,19.92,117.11,122,206.38,244.78,206.38C392.77,503.42,504,392.19,504,255,503.88,250.48,503.76,245.92,503.52,241.48Z"&gt;&lt;/path&gt;&lt;/svg&gt; [http://www.bayesian.org/resources/bayes.html](http://www.bayesian.org/resources/bayes.html)    
&lt;svg viewBox="0 0 448 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M448 360V24c0-13.3-10.7-24-24-24H96C43 0 0 43 0 96v320c0 53 43 96 96 96h328c13.3 0 24-10.7 24-24v-16c0-7.5-3.5-14.3-8.9-18.7-4.2-15.4-4.2-59.3 0-74.7 5.4-4.3 8.9-11.1 8.9-18.6zM128 134c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm0 64c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm253.4 250H96c-17.7 0-32-14.3-32-32 0-17.6 14.4-32 32-32h285.4c-1.9 17.1-1.9 46.9 0 64z"&gt;&lt;/path&gt;&lt;/svg&gt; S. Bertsch McGrayne (2011). *[The Theory That Would Not Die](https://www.amazon.co.uk/Theory-That-Would-Not-Die/dp/0300188226)*         
&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  &lt;g groupmode="layer" id="layer6" label="icon"&gt;    &lt;path style="stroke-width:0.07717" d="m 115.59247,222.50738 c -9.72601,0 -18.734334,7.07397 -24.986084,14.41694 -5.061076,5.95394 -7.591049,15.13238 -7.591049,22.77486 0,7.6402 2.870733,16.13879 7.931808,22.09274 6.152292,7.34297 12.778135,12.37522 22.603045,12.37522 8.83314,0 19.33786,-3.70766 25.389,-9.76105 6.1523,-6.05338 11.26931,-16.21737 11.26931,-25.04826 0,-8.73142 -2.39548,-19.18696 -8.54776,-25.24039 -6.15229,-6.15455 -17.33741,-11.61061 -26.06883,-11.61061 z m 174.6438,2.39944 c -10.12046,0 -18.35798,3.98058 -24.70919,11.93724 -5.15827,6.38628 -7.73967,13.66255 -7.73967,21.82831 0,8.27088 2.5814,15.59914 7.73967,21.98538 6.35064,7.95667 14.58873,11.93729 24.70919,11.93729 9.03149,0 16.67002,-3.25109 22.9212,-9.74241 6.25399,-6.59703 9.37846,-14.65259 9.37846,-24.18026 0,-9.422 -3.17646,-17.37639 -9.52708,-23.86775 -6.2495,-6.59477 -13.8428,-9.89721 -22.77258,-9.89721 z M 255.99998,7.9999981 C 119.03396,7.9999981 7.9999985,119.03394 7.9999985,255.99998 7.9999985,392.96602 119.03396,504 255.99998,504 392.96606,504 504,392.96602 504,255.99998 504,119.03394 392.96606,7.9999981 255.99998,7.9999981 Z M 197.17431,331.79065 h -45.93563 v -18.69931 c -4.66437,5.85506 -15.63869,11.82369 -20.40025,14.50172 -8.33473,4.66267 -19.65377,7.70067 -30.27265,7.70067 -17.167865,0 -32.44885,-5.425 -45.844653,-17.23173 -15.977193,-14.0903 -23.483472,-35.63322 -23.483472,-58.85447 0,-23.61798 8.186103,-42.47212 24.559999,-56.56242 12.999092,-11.21393 28.896046,-20.18949 45.766106,-20.18949 9.82264,0 21.93961,0.88269 30.57214,5.04865 4.96218,2.38076 13.84449,7.98548 19.10448,13.44381 v -98.50164 h 45.93564 v 229.34421 z m 157.21544,-21.13999 c -15.28099,17.58718 -36.66682,26.38303 -64.15348,26.38303 -27.58613,0 -49.01942,-8.79585 -64.30436,-26.38303 -12.60069,-14.44803 -18.90387,-32.19228 -18.90387,-53.23507 0,-18.94908 6.35065,-35.75132 19.0525,-50.4079 15.37988,-17.69285 37.26185,-26.54011 65.64139,-26.54011 26.09766,0 46.93585,8.84558 62.51694,26.54011 12.70185,14.44806 19.05247,31.66734 19.05247,51.66468 0.003,20.20586 -6.29921,37.53085 -18.90159,51.97886 z m 38.76899,-199.21794 c 5.35888,-5.35888 11.85868,-8.03746 19.49892,-8.03746 7.64024,0 14.14005,2.67858 19.49893,8.03746 5.35888,5.25945 8.03746,11.70955 8.03746,19.35034 0,7.73965 -2.67858,14.28864 -8.03746,19.64753 -5.25944,5.25944 -11.75925,7.8883 -19.49893,7.8883 -7.64247,0 -14.14227,-2.67861 -19.49892,-8.0375 -5.2594,-5.35885 -7.88829,-11.85871 -7.88829,-19.49892 -0.003,-7.6402 2.62889,-14.0903 7.88829,-19.35029 z m 43.91029,220.24265 H 388.24626 V 185.84118 h 48.82277 z" id="path2"&gt;&lt;/path&gt;  &lt;/g&gt;&lt;/svg&gt; S. Fienberg (2006). [When did Bayesian inference become Bayesian?](doi:10.1214/06-BA101)
]

---

count: false
# Bayesian inference

## Basic ideas

### Direct expression of uncertainty about unknown parameters

&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;
.content-box-lightblue[
"There is an 89% probability that the absolute increase in major bleeds is less than 10 percent with low-dose PLT 
transfusions"  .small[.alignright[(&lt;svg viewBox="0 0 384 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  &lt;g label="icon" id="layer6" groupmode="layer"&gt;    &lt;path id="path2" d="M 120.19265,177.73779 C 123.18778,77.35076 64.277527,63.999998 64.277527,63.999998 v 31.26245 C 40.834519,83.611374 18.32863,81.929634 18.32863,81.929634 V 337.10903 c 0,0 98.10414,-11.41744 98.10414,84.40952 0,0 36.58424,-153.37442 248.86103,26.48145 0,-61.59342 0.37757,-216.93925 0.37757,-268.28471 C 169.9561,37.131382 120.1931,177.73779 120.1931,177.73779 Z m 187.20631,173.82056 -12.37599,-97.65441 h -0.448 l -40.72819,97.65441 h -17.55994 l -38.9362,-97.65441 h -0.448 l -14.17589,97.65441 h -43.87514 l 28.8015,-169.61925 h 43.42716 l 34.43518,90.6496 36.46566,-90.6496 h 43.87513 l 25.6817,169.61925 h -44.13938 z" style="stroke-width:0.0675239"&gt;&lt;/path&gt;  &lt;/g&gt;&lt;/svg&gt; [Tinmouth et al, *Transfusion*, 2004](https://pubmed.ncbi.nlm.nih.gov/15584985))]]]

&lt;span style="display:block; margin-top: -15px ;"&gt;&lt;/span&gt;
&lt;img src="./img/unnamed-chunk-3-1.png" style="display: block; margin: auto;" width="40%" title="The graph shows the distribution of the % absolute increase in risk, given the observed data. As most of this distribution is below 10%, then we can conclude that the risk is limited"&gt;

---

count: false
# Bayesian inference 

## Basic ideas

&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

&lt;img src="./img/unnamed-chunk-4-1.png" style="display: block; margin: auto;" width="30%" fig.align="center" title="An example of a diagnostic problem. If we do not consider the 'background prevalence' of the disease, we get an incomplete picture. Bayes theorem allows us to account of this information formally"&gt;

- Suppose a patient is tested for HIV. The test comes up negative (&amp;ndash;ve)

- Given the assumptions/model, this indicates **fairly strong** evidence against the hypothesis that the true status is "Disease", so basically `\(p=0.04\)`

---
count: false
# Bayesian inference

## Basic ideas

&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

&lt;img src="./img/unnamed-chunk-5-1.png" style="display: block; margin: auto;" width="30%" fig.align="center" title="An example of a diagnostic problem. If we do not consider the 'background prevalence' of the disease, we get an incomplete picture. Bayes theorem allows us to account of this information formally"&gt;

- Suppose a patient is tested for HIV. The test comes up negative (&amp;ndash;ve)

- Given the assumptions/model, this indicates **fairly strong** evidence against the hypothesis that the true status is "Disease", so basically `\(p=0.04\)`

- But: how **prevalent** is the disease in the population?
  - We can model our prior knowledge about this and combine this information with the evidence from the data (using **Bayes theorem**)
&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

$$ \Pr(\style{font-family:inherit;}{\text{Disease}} \mid \style{font-family:inherit;}{\text{-ve}}) = \frac{\Pr(\style{font-family:inherit;}{\text{Disease}})\Pr(\style{font-family:inherit;}{\text{-ve}} \mid \style{font-family:inherit;}{\text{Disease}})}{\Pr(\style{font-family:inherit;}{\text{-ve}})} $$

- Update uncertainty given the evidence provided by the data

---

# Bayesian inference  

## Prior vs posterior

- The evidence **from the data alone** tells us that the observed result is extremely unlikely under the hypothesis of "Disease"
- This is strongly dependent on the **context**, as provided by the prior knowledge/epistemic uncertainty, though!

&lt;img src="./img/unnamed-chunk-6-1.png" style="display: block; margin: auto;" width="35%" title="The posterior distribution can depend strongly on the value assumed for the prior. In general, if the prior is too strong (for example, if you assume that no-one has the disease in the first place), then the posterior will be completely driven by it. In this example, if the prior prevalence of the disease is 80%, then the posterior after observing a negative test is only about 14% chance of being infected"&gt;

---

count: false
# Bayesian inference 

## Basic ideas

- A Bayesian model specifies a **full probability distribution** to describe uncertainty

- This applies to    
   - **Data**, which are subject to **sampling variability**
   - **Parameters** (or hypotheses), typically unobservable and thus subject to **epistemic uncertainty**
   - And even future, yet unobserved realisations of the observable variables (data) 
--


- Probability is the only languange in the Bayesian framework to assess any form of imperfect information or knowledge
   - No need to distinguish between probability and confidence
   - Before even seeing the data, we need to identify a suitable probability distribution to describe the overall uncertainty about the data `\(\boldsymbol{y}\)` and the parameters `\(\boldsymbol\theta\)`
   
--

$$ p(\boldsymbol{y},\boldsymbol\theta)=p(\boldsymbol\theta)p(\boldsymbol y\mid\boldsymbol\theta) = p(\boldsymbol y)p(\boldsymbol\theta\mid \boldsymbol y) $$
&amp;emsp; from which we derive Bayes Theorem
   
$$ p(\boldsymbol\theta\mid \boldsymbol y) = \frac{p(\boldsymbol\theta)p(\boldsymbol y\mid\boldsymbol\theta)}{p(\boldsymbol y)} $$

- **Express beliefs in form of a probability distribution**

---

# Bayesian modelling

## (Super) silly example: drug

.pull-left[
**Existing knowledge**
- Population registries
- Observational studies
- Small/pilot RCTs
- Expert opinion
]
.pull-right[
]

&lt;span style="display:block; margin-top: -60px ;"&gt;&lt;/span&gt;
&lt;img src="./img/unnamed-chunk-7-1.png" style="display: block; margin: auto;" width="33%" title="The prior distribution shows the 'state of science' about the relevant model parameters before any new data are observed"&gt;
Encode the assumption that a drug has a response rate between 20% and 60%

---

count: false
# Bayesian modelling

## (Super) silly example: drug
.pull-left[
**Existing knowledge**
- Population registries
- Observational studies
- Small/pilot RCTs
- Expert opinion
]
.pull-right[
.alignright[
**Current data**
- Large(r) scale RCT
- Observational study
- Relevant summaries
]
]

&lt;span style="display:block; margin-top: -60px ;"&gt;&lt;/span&gt;
&lt;img src="./img/unnamed-chunk-8-1.png" style="display: block; margin: auto;" width="33%" title="The evidence provided by the actual data under the current modelling assumptions can be represented by the likelihood function. Note that the sampling distribution is a function of the data for a fixed value of the parameters, so it would not be directly comparable with the prior. However, we can consider the likelihood function (which depends on the unknown model parameters, given fixed value of the data), which is defined on the same scale of the prior and the posterior"&gt;
Observe a study with 150 responders out of 200 patients given the drug

---

count: false
# Bayesian modelling 

## (Super) silly example: drug

.pull-left[
**Existing knowledge**
- Population registries
- Observational studies
- Small/pilot RCTs
- Expert opinion
]
.pull-right[
.alignright[
**Current data**
- Large(r) scale RCT
- Observational study
- Relevant summaries
]
]

&lt;span style="display:block; margin-top: -60px ;"&gt;&lt;/span&gt;
&lt;img src="./img/unnamed-chunk-9-1.png" style="display: block; margin: auto;" width="33%" title="The posterior distribution is generally a compromise between the prior and the likelihood. The more definitive the evidence provided by the data (and hence the likelihood), the closer the posterior to the likelihood function"&gt;
Update knowledge to describe revised "state of science"

---

# .small[*But how can I form a prior? I know **nothing** about this parameter!*...]

---

count: false
# .small[*But how can I form a prior? I know **nothing** about this parameter!*...]

&lt;center&gt;&lt;img src="img/Silvio.jpg" background-size: contain; title="This is an example about statistical modelling of political data. I am personally very interested in politics and, as an Italian, at some point I became fed up with my country, who decided that having Berlusconi as prime minister was a good idea. US President Obama's look while Berlusconi checks out the US First Lady is a good summary of my own opinion of the Italian PM...";&gt;&lt;/center&gt;

---

count: false
# .small[*But how can I form a prior? I know **nothing** about this parameter!*...]

.pull-left[
&lt;center&gt;&lt;img src="img/chips.jpg" background-size: contain; title="So when I moved to the UK I was for a while reassured that I was living in a saner country. Until they also decided that somebody like Ms May was a good idea for a PM...";&gt;&lt;/center&gt;
]

--

.pull-right[
&lt;center&gt;&lt;img src="img/ohdeargod.jpg" background-size: contain; title="And imagine my despair when they also decided that somebody like Mr Johnson was an even better idea for PM...";&gt;&lt;/center&gt;
]

---

count: false
# .small[*But how can I form a prior? I know **nothing** about this parameter!*...]

- Predicting the output of the 2017 UK General Election using poll data (see [here](http://www.statistica.it/gianluca/post/2017-04-25-snap/) and subsequent posts)
  - Data: number of people out of the `\(N_i\)` respondents in poll `\(i\)` intending to vote for party `\(p\)` (multinomial counts)    
  - **Objective of estimation**: `\((\pi_1,\ldots,\pi_P)=\)` population vote share for each party    
  - Can model `\(\pi_p = \left(\phi_p\middle / \sum \phi_p \right)\)` and `\(\displaystyle \log(\phi_p) = \alpha_p + \beta_p X_p\)`

&lt;center&gt;&lt;img src="img/Election.png" width="40%" title="Anyway, the point is that we do have some knowledge about the thing we want to model in the first place... In the election example, we can pretend that we don't know anything, but this would actually mean that we would assume, before observing any data, that all the parties have more or less the same share of the vote. This is clearly not true (if anything based on the last election and the current parliament composition) and so we should encode this knowledge in our model"&gt;&lt;/center&gt;

---

# Covid-19 excess mortality in Italy

&lt;center&gt;&lt;img src=./img/Fig.1.png width='105%' title=''&gt;&lt;/center&gt; 

&lt;span style="display:block; margin-top: 30px ;"&gt;&lt;/span&gt;
.alignleft[.small[&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  &lt;g groupmode="layer" id="layer6" label="icon"&gt;    &lt;path style="stroke-width:0.07717" d="m 115.59247,222.50738 c -9.72601,0 -18.734334,7.07397 -24.986084,14.41694 -5.061076,5.95394 -7.591049,15.13238 -7.591049,22.77486 0,7.6402 2.870733,16.13879 7.931808,22.09274 6.152292,7.34297 12.778135,12.37522 22.603045,12.37522 8.83314,0 19.33786,-3.70766 25.389,-9.76105 6.1523,-6.05338 11.26931,-16.21737 11.26931,-25.04826 0,-8.73142 -2.39548,-19.18696 -8.54776,-25.24039 -6.15229,-6.15455 -17.33741,-11.61061 -26.06883,-11.61061 z m 174.6438,2.39944 c -10.12046,0 -18.35798,3.98058 -24.70919,11.93724 -5.15827,6.38628 -7.73967,13.66255 -7.73967,21.82831 0,8.27088 2.5814,15.59914 7.73967,21.98538 6.35064,7.95667 14.58873,11.93729 24.70919,11.93729 9.03149,0 16.67002,-3.25109 22.9212,-9.74241 6.25399,-6.59703 9.37846,-14.65259 9.37846,-24.18026 0,-9.422 -3.17646,-17.37639 -9.52708,-23.86775 -6.2495,-6.59477 -13.8428,-9.89721 -22.77258,-9.89721 z M 255.99998,7.9999981 C 119.03396,7.9999981 7.9999985,119.03394 7.9999985,255.99998 7.9999985,392.96602 119.03396,504 255.99998,504 392.96606,504 504,392.96602 504,255.99998 504,119.03394 392.96606,7.9999981 255.99998,7.9999981 Z M 197.17431,331.79065 h -45.93563 v -18.69931 c -4.66437,5.85506 -15.63869,11.82369 -20.40025,14.50172 -8.33473,4.66267 -19.65377,7.70067 -30.27265,7.70067 -17.167865,0 -32.44885,-5.425 -45.844653,-17.23173 -15.977193,-14.0903 -23.483472,-35.63322 -23.483472,-58.85447 0,-23.61798 8.186103,-42.47212 24.559999,-56.56242 12.999092,-11.21393 28.896046,-20.18949 45.766106,-20.18949 9.82264,0 21.93961,0.88269 30.57214,5.04865 4.96218,2.38076 13.84449,7.98548 19.10448,13.44381 v -98.50164 h 45.93564 v 229.34421 z m 157.21544,-21.13999 c -15.28099,17.58718 -36.66682,26.38303 -64.15348,26.38303 -27.58613,0 -49.01942,-8.79585 -64.30436,-26.38303 -12.60069,-14.44803 -18.90387,-32.19228 -18.90387,-53.23507 0,-18.94908 6.35065,-35.75132 19.0525,-50.4079 15.37988,-17.69285 37.26185,-26.54011 65.64139,-26.54011 26.09766,0 46.93585,8.84558 62.51694,26.54011 12.70185,14.44806 19.05247,31.66734 19.05247,51.66468 0.003,20.20586 -6.29921,37.53085 -18.90159,51.97886 z m 38.76899,-199.21794 c 5.35888,-5.35888 11.85868,-8.03746 19.49892,-8.03746 7.64024,0 14.14005,2.67858 19.49893,8.03746 5.35888,5.25945 8.03746,11.70955 8.03746,19.35034 0,7.73965 -2.67858,14.28864 -8.03746,19.64753 -5.25944,5.25944 -11.75925,7.8883 -19.49893,7.8883 -7.64247,0 -14.14227,-2.67861 -19.49892,-8.0375 -5.2594,-5.35885 -7.88829,-11.85871 -7.88829,-19.49892 -0.003,-7.6402 2.62889,-14.0903 7.88829,-19.35029 z m 43.91029,220.24265 H 388.24626 V 185.84118 h 48.82277 z" id="path2"&gt;&lt;/path&gt;  &lt;/g&gt;&lt;/svg&gt; [Blangiardo et al 2020](https://doi.org/%20https://doi.org/10.1371/journal.pone.0240286)]]

---

# Predicting outcome of football games

&lt;center&gt;&lt;img src=./img/eng-ita.png width='45%' title=''&gt;&lt;/center&gt;

&lt;span style="display:block; margin-top: -100px ;"&gt;&lt;/span&gt;
.alignleft[.small[&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M503.52,241.48c-.12-1.56-.24-3.12-.24-4.68v-.12l-.36-4.68v-.12a245.86,245.86,0,0,0-7.32-41.15c0-.12,0-.12-.12-.24l-1.08-4c-.12-.24-.12-.48-.24-.6-.36-1.2-.72-2.52-1.08-3.72-.12-.24-.12-.6-.24-.84-.36-1.2-.72-2.4-1.08-3.48-.12-.36-.24-.6-.36-1-.36-1.2-.72-2.28-1.2-3.48l-.36-1.08c-.36-1.08-.84-2.28-1.2-3.36a8.27,8.27,0,0,0-.36-1c-.48-1.08-.84-2.28-1.32-3.36-.12-.24-.24-.6-.36-.84-.48-1.2-1-2.28-1.44-3.48,0-.12-.12-.24-.12-.36-1.56-3.84-3.24-7.68-5-11.4l-.36-.72c-.48-1-.84-1.8-1.32-2.64-.24-.48-.48-1.08-.72-1.56-.36-.84-.84-1.56-1.2-2.4-.36-.6-.6-1.2-1-1.8s-.84-1.44-1.2-2.28c-.36-.6-.72-1.32-1.08-1.92s-.84-1.44-1.2-2.16a18.07,18.07,0,0,0-1.2-2c-.36-.72-.84-1.32-1.2-2s-.84-1.32-1.2-2-.84-1.32-1.2-1.92-.84-1.44-1.32-2.16a15.63,15.63,0,0,0-1.2-1.8L463.2,119a15.63,15.63,0,0,0-1.2-1.8c-.48-.72-1.08-1.56-1.56-2.28-.36-.48-.72-1.08-1.08-1.56l-1.8-2.52c-.36-.48-.6-.84-1-1.32-1-1.32-1.8-2.52-2.76-3.72a248.76,248.76,0,0,0-23.51-26.64A186.82,186.82,0,0,0,412,62.46c-4-3.48-8.16-6.72-12.48-9.84a162.49,162.49,0,0,0-24.6-15.12c-2.4-1.32-4.8-2.52-7.2-3.72a254,254,0,0,0-55.43-19.56c-1.92-.36-3.84-.84-5.64-1.2h-.12c-1-.12-1.8-.36-2.76-.48a236.35,236.35,0,0,0-38-4H255.14a234.62,234.62,0,0,0-45.48,5c-33.59,7.08-63.23,21.24-82.91,39-1.08,1-1.92,1.68-2.4,2.16l-.48.48H124l-.12.12.12-.12a.12.12,0,0,0,.12-.12l-.12.12a.42.42,0,0,1,.24-.12c14.64-8.76,34.92-16,49.44-19.56l5.88-1.44c.36-.12.84-.12,1.2-.24,1.68-.36,3.36-.72,5.16-1.08.24,0,.6-.12.84-.12C250.94,20.94,319.34,40.14,367,85.61a171.49,171.49,0,0,1,26.88,32.76c30.36,49.2,27.48,111.11,3.84,147.59-34.44,53-111.35,71.27-159,24.84a84.19,84.19,0,0,1-25.56-59,74.05,74.05,0,0,1,6.24-31c1.68-3.84,13.08-25.67,18.24-24.59-13.08-2.76-37.55,2.64-54.71,28.19-15.36,22.92-14.52,58.2-5,83.28a132.85,132.85,0,0,1-12.12-39.24c-12.24-82.55,43.31-153,94.31-170.51-27.48-24-96.47-22.31-147.71,15.36-29.88,22-51.23,53.16-62.51,90.36,1.68-20.88,9.6-52.08,25.8-83.88-17.16,8.88-39,37-49.8,62.88-15.6,37.43-21,82.19-16.08,124.79.36,3.24.72,6.36,1.08,9.6,19.92,117.11,122,206.38,244.78,206.38C392.77,503.42,504,392.19,504,255,503.88,250.48,503.76,245.92,503.52,241.48Z"&gt;&lt;/path&gt;&lt;/svg&gt; [Blog](http://www.statistica.it/gianluca/post/2021-07-10-euros-prediction-5/)]]

---

# Voting bias at the Eurovision 

&lt;center&gt;&lt;img src=./img/eurovision-1.png width='55%' title=''&gt;&lt;/center&gt;

---

class: thankyou-michelle 
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
