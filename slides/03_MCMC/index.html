<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>‚Å£3. Learning from data using MCMC and BUGS</title>
    <meta charset="utf-8" />
    <meta name="author" content="Gianluca Baio" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <script src="libs/freezeframe/freezeframe.min.js"></script>
    <script src="libs/xaringanExtra-freezeframe/freezeframe-init.js"></script>
    <script id="xaringanExtra-freezeframe-options" type="application/json">{"selector":"img[src$=\"gif\"]","trigger":"click","overlay":false,"responsive":true,"warnings":true}</script>
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <!-- (Re)Defines a bunch of LaTeX commands that can then be used directly in the .Rmd file as '\command{...}' -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      TeX: {
        /* This enables color macros */
        extensions: ["color.js"],
        Macros: {
          /* Probability & mathematical symbols */
          Pr: "{\\style{font-family:inherit; font-size: 110%;}{\\text{Pr}}}",
          exp: "{\\style{font-family:inherit; font-size: 105%;}{\\text{exp}}}",
          log: "{\\style{font-family:inherit; font-size: 105%;}{\\text{log}}}",
          ln: "{\\style{font-family:inherit; font-size: 105%;}{\\text{ln}}}",
          logit: "{\\style{font-family:inherit; font-size: 100%;}{\\text{logit}}}",
          HR: "{\\style{font-family:inherit; font-size: 105%;}{\\text{HR}}}",
          OR: "{\\style{font-family:inherit; font-size: 105%;}{\\text{OR}}}",
          E: "{\\style{font-family:inherit; font-size: 105%;}{\\text{E}}}",
          Var: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Var}}}",
          Cov: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Cov}}}",
          Corr: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Corr}}}",
          DIC: "{\\style{font-family:inherit; font-size: 105%;}{\\text{DIC}}}",
          se: "{\\style{font-family:inherit; font-size: 100%;}{\\text{se}}}",
          sd: "{\\style{font-family:inherit; font-size: 100%;}{\\text{sd}}}",
          /* Distributions */
          dnorm: "{\\style{font-family:inherit;}{\\text{Normal}}}",
          dt: "{\\style{font-family:inherit;}{\\text{t}}}",
          ddirch: "{\\style{font-family:inherit;}{\\text{Dirichlet}}}",
          dmulti: "{\\style{font-family:inherit;}{\\text{Multinomial}}}",
          dbeta: "{\\style{font-family:inherit;}{\\text{Beta}}}",
          dgamma: "{\\style{font-family:inherit;}{\\text{Gamma}}}",
          dbern: "{\\style{font-family:inherit;}{\\text{Bernoulli}}}",
          dbin: "{\\style{font-family:inherit;}{\\text{Binomial}}}",
          dpois: "{\\style{font-family:inherit;}{\\text{Poisson}}}",
          dweib: "{\\style{font-family:inherit;}{\\text{Weibull}}}",
          dexp: "{\\style{font-family:inherit;}{\\text{Exponential}}}",
          dlnorm: "{\\style{font-family:inherit;}{\\text{logNormal}}}",
          dunif: "{\\style{font-family:inherit;}{\\text{Uniform}}}",
          /* LaTeX formatting */
          bm: ["{\\boldsymbol #1}",1],
          /* These create macros to typeset numbers in maths with the basic font */
          0: "{\\style{font-family:inherit; font-size: 105%;}{\\text{0}}}",
          1: "{\\style{font-family:inherit; font-size: 105%;}{\\text{1}}}",
          3: "{\\style{font-family:inherit; font-size: 105%;}{\\text{2}}}",
          3: "{\\style{font-family:inherit; font-size: 105%;}{\\text{3}}}",
          4: "{\\style{font-family:inherit; font-size: 105%;}{\\text{4}}}",
          5: "{\\style{font-family:inherit; font-size: 105%;}{\\text{5}}}",
          6: "{\\style{font-family:inherit; font-size: 105%;}{\\text{6}}}",
          7: "{\\style{font-family:inherit; font-size: 105%;}{\\text{7}}}",
          8: "{\\style{font-family:inherit; font-size: 105%;}{\\text{8}}}",
          9: "{\\style{font-family:inherit; font-size: 105%;}{\\text{9}}}",
          /* Health economics quantities */
          icer: "{\\style{font-family:inherit; font-size: 100%;}{\\text{ICER}}}",
          nb: "{\\style{font-family:inherit; font-size: 100%;}{\\text{NB}}}",
          ol: "{\\style{font-family:inherit; font-size: 100%;}{\\text{OL}}}",
          ceac: "{\\style{font-family:inherit; font-size: 100%;}{\\text{CEAC}}}",
          evpi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVPI}}}",
          evppi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVPPI}}}",
          evsi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVSI}}}"
        }
      }
    });
    </script>
    <link rel="stylesheet" href="../assets/ucl-stats.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




class: title-slide

# &amp;#8291;3. Learning from data using MCMC and `BUGS`

## Gianluca Baio

### [Department of Statistical Science](https://www.ucl.ac.uk/statistics/) | University College London    

.title-small[
&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#00acee;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"&gt;&lt;/path&gt;&lt;/svg&gt;  [g.baio@ucl.ac.uk](mailto:g.baio@ucl.ac.uk)
&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#EA7600;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M503.52,241.48c-.12-1.56-.24-3.12-.24-4.68v-.12l-.36-4.68v-.12a245.86,245.86,0,0,0-7.32-41.15c0-.12,0-.12-.12-.24l-1.08-4c-.12-.24-.12-.48-.24-.6-.36-1.2-.72-2.52-1.08-3.72-.12-.24-.12-.6-.24-.84-.36-1.2-.72-2.4-1.08-3.48-.12-.36-.24-.6-.36-1-.36-1.2-.72-2.28-1.2-3.48l-.36-1.08c-.36-1.08-.84-2.28-1.2-3.36a8.27,8.27,0,0,0-.36-1c-.48-1.08-.84-2.28-1.32-3.36-.12-.24-.24-.6-.36-.84-.48-1.2-1-2.28-1.44-3.48,0-.12-.12-.24-.12-.36-1.56-3.84-3.24-7.68-5-11.4l-.36-.72c-.48-1-.84-1.8-1.32-2.64-.24-.48-.48-1.08-.72-1.56-.36-.84-.84-1.56-1.2-2.4-.36-.6-.6-1.2-1-1.8s-.84-1.44-1.2-2.28c-.36-.6-.72-1.32-1.08-1.92s-.84-1.44-1.2-2.16a18.07,18.07,0,0,0-1.2-2c-.36-.72-.84-1.32-1.2-2s-.84-1.32-1.2-2-.84-1.32-1.2-1.92-.84-1.44-1.32-2.16a15.63,15.63,0,0,0-1.2-1.8L463.2,119a15.63,15.63,0,0,0-1.2-1.8c-.48-.72-1.08-1.56-1.56-2.28-.36-.48-.72-1.08-1.08-1.56l-1.8-2.52c-.36-.48-.6-.84-1-1.32-1-1.32-1.8-2.52-2.76-3.72a248.76,248.76,0,0,0-23.51-26.64A186.82,186.82,0,0,0,412,62.46c-4-3.48-8.16-6.72-12.48-9.84a162.49,162.49,0,0,0-24.6-15.12c-2.4-1.32-4.8-2.52-7.2-3.72a254,254,0,0,0-55.43-19.56c-1.92-.36-3.84-.84-5.64-1.2h-.12c-1-.12-1.8-.36-2.76-.48a236.35,236.35,0,0,0-38-4H255.14a234.62,234.62,0,0,0-45.48,5c-33.59,7.08-63.23,21.24-82.91,39-1.08,1-1.92,1.68-2.4,2.16l-.48.48H124l-.12.12.12-.12a.12.12,0,0,0,.12-.12l-.12.12a.42.42,0,0,1,.24-.12c14.64-8.76,34.92-16,49.44-19.56l5.88-1.44c.36-.12.84-.12,1.2-.24,1.68-.36,3.36-.72,5.16-1.08.24,0,.6-.12.84-.12C250.94,20.94,319.34,40.14,367,85.61a171.49,171.49,0,0,1,26.88,32.76c30.36,49.2,27.48,111.11,3.84,147.59-34.44,53-111.35,71.27-159,24.84a84.19,84.19,0,0,1-25.56-59,74.05,74.05,0,0,1,6.24-31c1.68-3.84,13.08-25.67,18.24-24.59-13.08-2.76-37.55,2.64-54.71,28.19-15.36,22.92-14.52,58.2-5,83.28a132.85,132.85,0,0,1-12.12-39.24c-12.24-82.55,43.31-153,94.31-170.51-27.48-24-96.47-22.31-147.71,15.36-29.88,22-51.23,53.16-62.51,90.36,1.68-20.88,9.6-52.08,25.8-83.88-17.16,8.88-39,37-49.8,62.88-15.6,37.43-21,82.19-16.08,124.79.36,3.24.72,6.36,1.08,9.6,19.92,117.11,122,206.38,244.78,206.38C392.77,503.42,504,392.19,504,255,503.88,250.48,503.76,245.92,503.52,241.48Z"&gt;&lt;/path&gt;&lt;/svg&gt;  [https://gianluca.statistica.it/](https://gianluca.statistica.it/)
&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#EA7600;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M503.52,241.48c-.12-1.56-.24-3.12-.24-4.68v-.12l-.36-4.68v-.12a245.86,245.86,0,0,0-7.32-41.15c0-.12,0-.12-.12-.24l-1.08-4c-.12-.24-.12-.48-.24-.6-.36-1.2-.72-2.52-1.08-3.72-.12-.24-.12-.6-.24-.84-.36-1.2-.72-2.4-1.08-3.48-.12-.36-.24-.6-.36-1-.36-1.2-.72-2.28-1.2-3.48l-.36-1.08c-.36-1.08-.84-2.28-1.2-3.36a8.27,8.27,0,0,0-.36-1c-.48-1.08-.84-2.28-1.32-3.36-.12-.24-.24-.6-.36-.84-.48-1.2-1-2.28-1.44-3.48,0-.12-.12-.24-.12-.36-1.56-3.84-3.24-7.68-5-11.4l-.36-.72c-.48-1-.84-1.8-1.32-2.64-.24-.48-.48-1.08-.72-1.56-.36-.84-.84-1.56-1.2-2.4-.36-.6-.6-1.2-1-1.8s-.84-1.44-1.2-2.28c-.36-.6-.72-1.32-1.08-1.92s-.84-1.44-1.2-2.16a18.07,18.07,0,0,0-1.2-2c-.36-.72-.84-1.32-1.2-2s-.84-1.32-1.2-2-.84-1.32-1.2-1.92-.84-1.44-1.32-2.16a15.63,15.63,0,0,0-1.2-1.8L463.2,119a15.63,15.63,0,0,0-1.2-1.8c-.48-.72-1.08-1.56-1.56-2.28-.36-.48-.72-1.08-1.08-1.56l-1.8-2.52c-.36-.48-.6-.84-1-1.32-1-1.32-1.8-2.52-2.76-3.72a248.76,248.76,0,0,0-23.51-26.64A186.82,186.82,0,0,0,412,62.46c-4-3.48-8.16-6.72-12.48-9.84a162.49,162.49,0,0,0-24.6-15.12c-2.4-1.32-4.8-2.52-7.2-3.72a254,254,0,0,0-55.43-19.56c-1.92-.36-3.84-.84-5.64-1.2h-.12c-1-.12-1.8-.36-2.76-.48a236.35,236.35,0,0,0-38-4H255.14a234.62,234.62,0,0,0-45.48,5c-33.59,7.08-63.23,21.24-82.91,39-1.08,1-1.92,1.68-2.4,2.16l-.48.48H124l-.12.12.12-.12a.12.12,0,0,0,.12-.12l-.12.12a.42.42,0,0,1,.24-.12c14.64-8.76,34.92-16,49.44-19.56l5.88-1.44c.36-.12.84-.12,1.2-.24,1.68-.36,3.36-.72,5.16-1.08.24,0,.6-.12.84-.12C250.94,20.94,319.34,40.14,367,85.61a171.49,171.49,0,0,1,26.88,32.76c30.36,49.2,27.48,111.11,3.84,147.59-34.44,53-111.35,71.27-159,24.84a84.19,84.19,0,0,1-25.56-59,74.05,74.05,0,0,1,6.24-31c1.68-3.84,13.08-25.67,18.24-24.59-13.08-2.76-37.55,2.64-54.71,28.19-15.36,22.92-14.52,58.2-5,83.28a132.85,132.85,0,0,1-12.12-39.24c-12.24-82.55,43.31-153,94.31-170.51-27.48-24-96.47-22.31-147.71,15.36-29.88,22-51.23,53.16-62.51,90.36,1.68-20.88,9.6-52.08,25.8-83.88-17.16,8.88-39,37-49.8,62.88-15.6,37.43-21,82.19-16.08,124.79.36,3.24.72,6.36,1.08,9.6,19.92,117.11,122,206.38,244.78,206.38C392.77,503.42,504,392.19,504,255,503.88,250.48,503.76,245.92,503.52,241.48Z"&gt;&lt;/path&gt;&lt;/svg&gt;  [https://egon.stats.ucl.ac.uk/research/statistics-health-economics/](https://egon.stats.ucl.ac.uk/research/statistics-health-economics/)
&lt;svg viewBox="0 0 496 512" style="position:relative;display:inline-block;top:.1em;fill:black;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;&lt;/svg&gt;  [https://github.com/giabaio](https://github.com/giabaio)
&lt;svg viewBox="0 0 496 512" style="position:relative;display:inline-block;top:.1em;fill:black;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;&lt;/svg&gt;  [https://github.com/StatisticsHealthEconomics](https://github.com/StatisticsHealthEconomics)
&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#00acee;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"&gt;&lt;/path&gt;&lt;/svg&gt;  [@gianlubaio](https://twitter.com/gianlubaio)     
]

### STAT0019 - Bayesian Methods in Health Economics, UCL

&lt;!--
Adds a departmental logo on the right-bottom corner (Only with 'ucl-stats')
--&gt;
.logo-stats[]

&lt;!--
Can also add sticky notes:
&lt;p style="position: absolute; top:75%; left:2.5%; font-family: Nanum Pen Script; font-size:85%; text-decoration: none; color: #000; background: #ffc; display: block; height:6.3em; width:6.3em; padding: .5em; box-shadow: 5px 5px 7px rgba(33,33,33,.7); transform: rotate(6deg); border-bottom-right-radius: 60px 5px;"&gt;Check out our departmental podcast "Random Talks" on Soundcloud!&amp;nbsp;&lt;a href="https://soundcloud.com/uclsound/sets/sample-space"; title="Random Talks"&gt;&lt;svg viewBox="0 0 640 512" style="position:relative;display:inline-block;top:.1em;fill:#FE5000;height:0.8em;bottom:1em;" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;path d="M111.4 256.3l5.8 65-5.8 68.3c-.3 2.5-2.2 4.4-4.4 4.4s-4.2-1.9-4.2-4.4l-5.6-68.3 5.6-65c0-2.2 1.9-4.2 4.2-4.2 2.2 0 4.1 2 4.4 4.2zm21.4-45.6c-2.8 0-4.7 2.2-5 5l-5 105.6 5 68.3c.3 2.8 2.2 5 5 5 2.5 0 4.7-2.2 4.7-5l5.8-68.3-5.8-105.6c0-2.8-2.2-5-4.7-5zm25.5-24.1c-3.1 0-5.3 2.2-5.6 5.3l-4.4 130 4.4 67.8c.3 3.1 2.5 5.3 5.6 5.3 2.8 0 5.3-2.2 5.3-5.3l5.3-67.8-5.3-130c0-3.1-2.5-5.3-5.3-5.3zM7.2 283.2c-1.4 0-2.2 1.1-2.5 2.5L0 321.3l4.7 35c.3 1.4 1.1 2.5 2.5 2.5s2.2-1.1 2.5-2.5l5.6-35-5.6-35.6c-.3-1.4-1.1-2.5-2.5-2.5zm23.6-21.9c-1.4 0-2.5 1.1-2.5 2.5l-6.4 57.5 6.4 56.1c0 1.7 1.1 2.8 2.5 2.8s2.5-1.1 2.8-2.5l7.2-56.4-7.2-57.5c-.3-1.4-1.4-2.5-2.8-2.5zm25.3-11.4c-1.7 0-3.1 1.4-3.3 3.3L47 321.3l5.8 65.8c.3 1.7 1.7 3.1 3.3 3.1 1.7 0 3.1-1.4 3.1-3.1l6.9-65.8-6.9-68.1c0-1.9-1.4-3.3-3.1-3.3zm25.3-2.2c-1.9 0-3.6 1.4-3.6 3.6l-5.8 70 5.8 67.8c0 2.2 1.7 3.6 3.6 3.6s3.6-1.4 3.9-3.6l6.4-67.8-6.4-70c-.3-2.2-2-3.6-3.9-3.6zm241.4-110.9c-1.1-.8-2.8-1.4-4.2-1.4-2.2 0-4.2.8-5.6 1.9-1.9 1.7-3.1 4.2-3.3 6.7v.8l-3.3 176.7 1.7 32.5 1.7 31.7c.3 4.7 4.2 8.6 8.9 8.6s8.6-3.9 8.6-8.6l3.9-64.2-3.9-177.5c-.4-3-2-5.8-4.5-7.2zm-26.7 15.3c-1.4-.8-2.8-1.4-4.4-1.4s-3.1.6-4.4 1.4c-2.2 1.4-3.6 3.9-3.6 6.7l-.3 1.7-2.8 160.8s0 .3 3.1 65.6v.3c0 1.7.6 3.3 1.7 4.7 1.7 1.9 3.9 3.1 6.4 3.1 2.2 0 4.2-1.1 5.6-2.5 1.7-1.4 2.5-3.3 2.5-5.6l.3-6.7 3.1-58.6-3.3-162.8c-.3-2.8-1.7-5.3-3.9-6.7zm-111.4 22.5c-3.1 0-5.8 2.8-5.8 6.1l-4.4 140.6 4.4 67.2c.3 3.3 2.8 5.8 5.8 5.8 3.3 0 5.8-2.5 6.1-5.8l5-67.2-5-140.6c-.2-3.3-2.7-6.1-6.1-6.1zm376.7 62.8c-10.8 0-21.1 2.2-30.6 6.1-6.4-70.8-65.8-126.4-138.3-126.4-17.8 0-35 3.3-50.3 9.4-6.1 2.2-7.8 4.4-7.8 9.2v249.7c0 5 3.9 8.6 8.6 9.2h218.3c43.3 0 78.6-35 78.6-78.3.1-43.6-35.2-78.9-78.5-78.9zm-296.7-60.3c-4.2 0-7.5 3.3-7.8 7.8l-3.3 136.7 3.3 65.6c.3 4.2 3.6 7.5 7.8 7.5 4.2 0 7.5-3.3 7.5-7.5l3.9-65.6-3.9-136.7c-.3-4.5-3.3-7.8-7.5-7.8zm-53.6-7.8c-3.3 0-6.4 3.1-6.4 6.7l-3.9 145.3 3.9 66.9c.3 3.6 3.1 6.4 6.4 6.4 3.6 0 6.4-2.8 6.7-6.4l4.4-66.9-4.4-145.3c-.3-3.6-3.1-6.7-6.7-6.7zm26.7 3.4c-3.9 0-6.9 3.1-6.9 6.9L227 321.3l3.9 66.4c.3 3.9 3.1 6.9 6.9 6.9s6.9-3.1 6.9-6.9l4.2-66.4-4.2-141.7c0-3.9-3-6.9-6.9-6.9z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp;&lt;/p&gt;

&lt;p style="position: absolute; top:53%; left:6.5%; font-family: Nanum Pen Script; font-size:85%; text-decoration: none; color: #000; background: #ffc; display: block; height:6.3em; width:6.3em; padding: .5em; box-shadow: 5px 5px 7px rgba(33,33,33,.7); transform: rotate(6deg); border-bottom-right-radius: 60px 5px;"&gt;Follow our departmental social media accounts&amp;nbsp;&lt;a href="https://twitter.com/stats_ucl"; title="@stats_UCL"&gt;&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#00acee;height:0.8em;bottom:1em;" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://www.linkedin.com/in/statistical-science-ucl-906b9a201"; title="LinkedIn"&gt;&lt;svg viewBox="0 0 448 512" style="position:relative;display:inline-block;top:.1em;fill:#2867b2;height:0.8em;bottom:1em;" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp;&lt;/p&gt;
--&gt;

&lt;!-- This adds a footer (optional and with other possibilities...) 
     For example, can use &lt;span&gt;&lt;a href="https://gianluca.statistica.it/"&gt;&lt;img src="assets/logo.png" title="Go home" width="2.0%"&gt;&lt;/a&gt;&lt;/span&gt; to add the Samp Tux log,
     or change the bottom space to align the text, etc
.footer-left[
&lt;span style="position: relative; bottom: 0px; color: #D5D5D5;"&gt; &amp;nbsp; &amp;copy; Gianluca Baio (UCL)&lt;/span&gt;
]
--&gt;


---

layout: true

.my-footer[ 
.alignleft[
&amp;nbsp; &amp;copy; Gianluca Baio (UCL) &amp;nbsp;&lt;a href="https://twitter.com/giabaio"; title="Follow me on Twitter"&gt;&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#bcc0c4;height:0.8em;bottom:1em;" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://github.com/giabaio"; title="Check out my repos"&gt;&lt;svg viewBox="0 0 496 512" style="position:relative;display:inline-block;top:.1em;fill:#bcc0c4;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="mailto:g.baio@ucl.ac.uk"; title="Email me"&gt;&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#bcc0c4;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://gianluca.statistica.it"; title="Visit my website"&gt;&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#bcc0c4;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;path d="M503.52,241.48c-.12-1.56-.24-3.12-.24-4.68v-.12l-.36-4.68v-.12a245.86,245.86,0,0,0-7.32-41.15c0-.12,0-.12-.12-.24l-1.08-4c-.12-.24-.12-.48-.24-.6-.36-1.2-.72-2.52-1.08-3.72-.12-.24-.12-.6-.24-.84-.36-1.2-.72-2.4-1.08-3.48-.12-.36-.24-.6-.36-1-.36-1.2-.72-2.28-1.2-3.48l-.36-1.08c-.36-1.08-.84-2.28-1.2-3.36a8.27,8.27,0,0,0-.36-1c-.48-1.08-.84-2.28-1.32-3.36-.12-.24-.24-.6-.36-.84-.48-1.2-1-2.28-1.44-3.48,0-.12-.12-.24-.12-.36-1.56-3.84-3.24-7.68-5-11.4l-.36-.72c-.48-1-.84-1.8-1.32-2.64-.24-.48-.48-1.08-.72-1.56-.36-.84-.84-1.56-1.2-2.4-.36-.6-.6-1.2-1-1.8s-.84-1.44-1.2-2.28c-.36-.6-.72-1.32-1.08-1.92s-.84-1.44-1.2-2.16a18.07,18.07,0,0,0-1.2-2c-.36-.72-.84-1.32-1.2-2s-.84-1.32-1.2-2-.84-1.32-1.2-1.92-.84-1.44-1.32-2.16a15.63,15.63,0,0,0-1.2-1.8L463.2,119a15.63,15.63,0,0,0-1.2-1.8c-.48-.72-1.08-1.56-1.56-2.28-.36-.48-.72-1.08-1.08-1.56l-1.8-2.52c-.36-.48-.6-.84-1-1.32-1-1.32-1.8-2.52-2.76-3.72a248.76,248.76,0,0,0-23.51-26.64A186.82,186.82,0,0,0,412,62.46c-4-3.48-8.16-6.72-12.48-9.84a162.49,162.49,0,0,0-24.6-15.12c-2.4-1.32-4.8-2.52-7.2-3.72a254,254,0,0,0-55.43-19.56c-1.92-.36-3.84-.84-5.64-1.2h-.12c-1-.12-1.8-.36-2.76-.48a236.35,236.35,0,0,0-38-4H255.14a234.62,234.62,0,0,0-45.48,5c-33.59,7.08-63.23,21.24-82.91,39-1.08,1-1.92,1.68-2.4,2.16l-.48.48H124l-.12.12.12-.12a.12.12,0,0,0,.12-.12l-.12.12a.42.42,0,0,1,.24-.12c14.64-8.76,34.92-16,49.44-19.56l5.88-1.44c.36-.12.84-.12,1.2-.24,1.68-.36,3.36-.72,5.16-1.08.24,0,.6-.12.84-.12C250.94,20.94,319.34,40.14,367,85.61a171.49,171.49,0,0,1,26.88,32.76c30.36,49.2,27.48,111.11,3.84,147.59-34.44,53-111.35,71.27-159,24.84a84.19,84.19,0,0,1-25.56-59,74.05,74.05,0,0,1,6.24-31c1.68-3.84,13.08-25.67,18.24-24.59-13.08-2.76-37.55,2.64-54.71,28.19-15.36,22.92-14.52,58.2-5,83.28a132.85,132.85,0,0,1-12.12-39.24c-12.24-82.55,43.31-153,94.31-170.51-27.48-24-96.47-22.31-147.71,15.36-29.88,22-51.23,53.16-62.51,90.36,1.68-20.88,9.6-52.08,25.8-83.88-17.16,8.88-39,37-49.8,62.88-15.6,37.43-21,82.19-16.08,124.79.36,3.24.72,6.36,1.08,9.6,19.92,117.11,122,206.38,244.78,206.38C392.77,503.42,504,392.19,504,255,503.88,250.48,503.76,245.92,503.52,241.48Z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp;
]
.aligncenter[
&amp;#8291;3. Learning from data using MCMC and `BUGS` 
]
.alignright[
&amp;nbsp;&lt;a target="_self" href="https://egon.stats.ucl.ac.uk/static/stat0019/"; title="Back to STAT0019 website"&gt;&lt;svg viewBox="0 0 576 512" style="position:relative;display:inline-block;top:.1em;fill:#bcc0c4;height:1em;bottom:1em;" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;path d="M280.37 148.26L96 300.11V464a16 16 0 0 0 16 16l112.06-.29a16 16 0 0 0 15.92-16V368a16 16 0 0 1 16-16h64a16 16 0 0 1 16 16v95.64a16 16 0 0 0 16 16.05L464 480a16 16 0 0 0 16-16V300L295.67 148.26a12.19 12.19 0 0 0-15.3 0zM571.6 251.47L488 182.56V44.05a12 12 0 0 0-12-12h-56a12 12 0 0 0-12 12v72.61L318.47 43a48 48 0 0 0-61 0L4.34 251.47a12 12 0 0 0-1.6 16.9l25.5 31A12 12 0 0 0 45.15 301l235.22-193.74a12.19 12.19 0 0 1 15.3 0L530.9 301a12 12 0 0 0 16.9-1.6l25.5-31a12 12 0 0 0-1.7-16.93z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp; STAT0019 
]
] 

---

# Summary 

- Already seen how to make predictions based on parameters with *known* uncertainty distributions

- Here we **learn** about parameters from **observed data** using *Bayes theorem*

- Simple example &amp;ndash; trial with binary outcome
   - *"conjugate"*: no simulation needed

- Simulating posterior distributions of unknowns given data, using **MCMC (Markov Chain Monte Carlo)** in `BUGS`
   - Practical issues: putting data in 
   - Convergence (knowing which / how many simulations to save)

- Expressing full uncertainty on any function / transformation of unknown parameters

&lt;span style="display:block; margin-top: 4rem ;"&gt;&lt;/span&gt;
.content-box-beamer[
### References 
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

&lt;svg viewBox="0 0 448 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;
  [ comment ]
  &lt;path d="M448 360V24c0-13.3-10.7-24-24-24H96C43 0 0 43 0 96v320c0 53 43 96 96 96h328c13.3 0 24-10.7 24-24v-16c0-7.5-3.5-14.3-8.9-18.7-4.2-15.4-4.2-59.3 0-74.7 5.4-4.3 8.9-11.1 8.9-18.6zM128 134c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm0 64c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm253.4 250H96c-17.7 0-32-14.3-32-32 0-17.6 14.4-32 32-32h285.4c-1.9 17.1-1.9 46.9 0 64z"&gt;&lt;/path&gt;
&lt;/svg&gt; &lt;i&gt;The BUGS Book&lt;/i&gt;, chapters 3, 4 .button[&lt;img src="../img/ucl-icon.png" width="18%"&gt; [Library](https://ebookcentral.proquest.com/lib/ucl/reader.action?docID=1501675)] .button[&lt;img src="../img/routledge.png" width="10%"&gt; [Book website](https://www.routledge.com/The-BUGS-Book-A-Practical-Introduction-to-Bayesian-Analysis/Lunn-Jackson-Best-Thomas-Spiegelhalter/p/book/9781584888499)]

&lt;svg viewBox="0 0 448 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;
  [ comment ]
  &lt;path d="M448 360V24c0-13.3-10.7-24-24-24H96C43 0 0 43 0 96v320c0 53 43 96 96 96h328c13.3 0 24-10.7 24-24v-16c0-7.5-3.5-14.3-8.9-18.7-4.2-15.4-4.2-59.3 0-74.7 5.4-4.3 8.9-11.1 8.9-18.6zM128 134c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm0 64c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm253.4 250H96c-17.7 0-32-14.3-32-32 0-17.6 14.4-32 32-32h285.4c-1.9 17.1-1.9 46.9 0 64z"&gt;&lt;/path&gt;
&lt;/svg&gt; &lt;i&gt;Bayesian Methods in Health Economics&lt;/i&gt;, chapters 2, 4 .button[&lt;img src="../img/ucl-icon.png" width="18%"&gt; [Library](https://ucl.rl.talis.com/link?url=http%3A%2F%2Flibproxy.ucl.ac.uk%2Flogin%3Fqurl%3Dhttps%253A%252F%252Fdoi.org%252F10.1201%252Fb13099&amp;sig=3aebc20479b70f36a22609520951c13ac9cfd52cb8fbf0b8d1c46a857432d1a6)] .button[&lt;img src="../img/routledge.png" width="7%"&gt; [Book website (CRC)](https://www-taylorfrancis-com.libproxy.ucl.ac.uk/books/9780429111396)] .button[&lt;i class="fab fa-firefox"&gt;&lt;/i&gt; [Book website](http://www.statistica.it/gianluca/bmhe)] .button[&lt;i class="fab fa-github"&gt;&lt;/i&gt; [Code](https://github.com/giabaio/BCEA)]
]

---

# Bayes Theorem 


## Updating beliefs with new evidence

- External evidence about unknown quantities `\(\theta\)` **that is not based on current data** is expressed as a **prior** probability distribution `\(p(\theta)\)`
- Evidence from available data `\(y\)` expressed as **sampling distribution**  `\(p(y\mid \theta)\)`

--

Two sources of evidence combined using **Bayes theorem**:

`$$p(\theta \mid y) = p(\theta) \times \frac{p(y\mid \theta)}{p(y)}$$` which is essentially

`$$p(\theta \mid y) \propto p(\theta) \times p(y\mid \theta)$$`

&lt;span style="display:block; margin-top: 2rem ;"&gt;&lt;/span&gt;
&lt;center style="color: #035AA6;"&gt; &lt;b&gt;Posterior&lt;/b&gt; \(\propto\) &lt;b&gt;Prior&lt;/b&gt; \(\times\) &lt;b&gt;Likelihood&lt;/b&gt; &lt;/center&gt;

&lt;!--
`$$\mbox{posterior} \propto \mbox{prior} \times \mbox{likelihood}$$`
--&gt;

&lt;span style="display:block; margin-top: 1rem ;"&gt;&lt;/span&gt;
... Posterior becomes your prior when next piece of evidence arrives...

---

# Bayesian methods for fitting models

## Practical benefits

- Ability to **synthesise** multiple datasets / sources of evidence in coherent manner

- ... Allows complexities about real-world data to be modelled (via MCMC methods)

- Naturally provides **predictions** of future events

- Full allowance for **uncertainty** in conclusions

- **Intuitive** communication
   - express uncertainty by probability statements about unknowns

--

&lt;span style="display:block; margin-top: 1 ;"&gt;&lt;/span&gt;
## Challenges

- Harder to implement than classical "frequentist" methods

- Extra source of information (the prior) &amp;ndash; can be tricky to specify...

---

# Choice of prior distributions

- **"Vague" priors**: typically distributions with big variances (*on a suitable scale*!), eg `mu ~ dnorm(0, 0.00001)` (**NB**: precision=0.00001 `\(\Rightarrow\)` variance=100000!)

.pull-left[
&lt;img src="./img/unnamed-chunk-2-1.png" style="display: block; margin: auto;" width="85%" title="This is a vague prior for the mean of a Normal distribution. It may be perfectly OK to assume that possible values span effectively from -1000 to 1000, depending on the meaning of the underlying variable. Or it may be way too vague (if, for instance, the underlying variable is the difference in the blood pressure between patients treated with a new drug or with placebo"&gt;
]
.pull-right[
&lt;img src="./img/unnamed-chunk-3-1.png" style="display: block; margin: auto;" width="85%" title="This is the same distribution, except this time is defined on the log sd of that Normal distribution. This would imply impossibly large values may still be reasonable, before we observe data and this may have implications especially if the information in the data is very limited"&gt;
]

&lt;span style="display:block; margin-top: -40px ;"&gt;&lt;/span&gt;
- **NB**: Beware of the implications of your prior &amp;ndash; are you assuming too much (unrealistic) variance?    
--

- More recent proposal: **Penalised Complexity** (PC) Priors 
   - Use "default" distributional assumptions; penalise deviations from (= added complexity in comparison to) a simpler, base model &amp;ndash; can be very hard to think about and construct
   - (**Very** technical) &lt;svg viewBox="0 0 384 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zM64 72c0-4.42 3.58-8 8-8h80c4.42 0 8 3.58 8 8v16c0 4.42-3.58 8-8 8H72c-4.42 0-8-3.58-8-8V72zm0 64c0-4.42 3.58-8 8-8h80c4.42 0 8 3.58 8 8v16c0 4.42-3.58 8-8 8H72c-4.42 0-8-3.58-8-8v-16zm192.81 248H304c8.84 0 16 7.16 16 16s-7.16 16-16 16h-47.19c-16.45 0-31.27-9.14-38.64-23.86-2.95-5.92-8.09-6.52-10.17-6.52s-7.22.59-10.02 6.19l-7.67 15.34a15.986 15.986 0 0 1-14.31 8.84c-.38 0-.75-.02-1.14-.05-6.45-.45-12-4.75-14.03-10.89L144 354.59l-10.61 31.88c-5.89 17.66-22.38 29.53-41 29.53H80c-8.84 0-16-7.16-16-16s7.16-16 16-16h12.39c4.83 0 9.11-3.08 10.64-7.66l18.19-54.64c3.3-9.81 12.44-16.41 22.78-16.41s19.48 6.59 22.77 16.41l13.88 41.64c19.77-16.19 54.05-9.7 66 14.16 2.02 4.06 5.96 6.5 10.16 6.5zM377 105L279.1 7c-4.5-4.5-10.6-7-17-7H256v128h128v-6.1c0-6.3-2.5-12.4-7-16.9z"&gt;&lt;/path&gt;&lt;/svg&gt; [paper](https://projecteuclid.org/euclid.ss/1491465621)
   
---

# Choice of prior distributions

**Informative priors**: from previous studies, or *elicited* from experts  

- May be difficult to derive, so present sensitivity analysis to different choices    
- If exact choice of vague prior is influential `\(\Rightarrow\)` need more data or informative prior    
- Put prior on "**natural** scale" (as opposed to "*original* scale"!) parameters
   - Easier to include genuine information &amp;ndash; **more on this later!**
   - For instance: place a prior on `\(\theta \sim \style{font-family:inherit;}{\text{Gamma}}(\eta,\lambda)\)` ...

&lt;span style="display:block; margin-top: -24px ;"&gt;&lt;/span&gt;

.pull-left[
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
&lt;img src="./img/unnamed-chunk-4-1.png" style="display: block; margin: auto;" width="90%" title="It's generally hard to elicit prior on mathematical (original) parameters, such as rates, shapes, scales, because they don't have a physical meaning. In this case, we can make priors on the mean and sd of an underlying Gamma distribution, for which we may be able to elicit some relevant information and then turn them into the priors for the actual mathematical parameters that are required to model the Gamma distribution"&gt;
]

.pull-right[
&lt;span style="display:block; margin-top: -40px ;"&gt;&lt;/span&gt;

```r
&gt; # Simulates from priors for mu and sigma
&gt; mu=rlnorm(10000,5.2,.2)
&gt; sigma=rexp(10000,.35)
&gt; # Check interval estimates
&gt; quantile(mu,c(.025,.975))
```

```
    2.5%    97.5% 
122.7655 270.3207 
```

```r
&gt; quantile(sigma,c(.025,.975))
```

```
       2.5%       97.5% 
 0.07482428 10.83392815 
```

```r
&gt; # Simulates from priors for lambda and eta
&gt; lambda=sqrt(mu/sigma^2)
&gt; eta=mu*lambda
```
]

---

name: conjugacy
# Bayesian modelling of binary data

Suppose `\(\theta\)` is the true underlying success rate (proportion) of a drug

Assume a `\(\color{#FF851B}{\style{font-family:inherit;}{\text{Beta}}(a, b)}\)` prior distribution  for `\(\theta\)`

`$$\style{font-family:inherit;}{\text{Prior}}   \propto  \theta^{a -1} (1-\theta)^{ b - 1}$$`

If we observe `\(r\)` successes out of `\(n\)` trials, the Binomial distribution means that

$$\style{font-family:inherit;}{\text{Likelihood}}  \propto  \theta^{r} (1-\theta)^{n- r} $$

Then by Bayes theorem
`\begin{align}
\style{font-family:inherit;}{\text{Posterior}} &amp; \propto \theta^{a -1} (1-\theta)^{ b -1}
\theta^{r} (1-\theta)^{n-r}  \\
&amp; \propto \theta^{a+r-1} (1-\theta)^{b+n-r-1}  \\
&amp;  = \style{font-family:inherit;}{\text{Beta}}(a+r,b+  n-r)
\end{align}`

**Beta** prior + **Binomial** data = **Beta** posterior distribution

---

# Bayesian modelling of binary data 

### See &lt;a href="../02_BUGS/#beta-tricks"&gt;Lecture 2&lt;/a&gt;

So: `\(\displaystyle\left\{ \begin{array}{l} \theta\sim \style{font-family:inherit;}{\text{Beta}}(0,0) \\ y_0\sim \style{font-family:inherit;}{\text{Binomial}}(\theta,n_0)\end{array} \right. \qquad \Rightarrow\qquad  \theta\mid y_0,n_0 \sim \style{font-family:inherit;}{\text{Beta}}(y_0, n_0-y_0)\)`

- Intuition: a `\(\style{font-family:inherit;}{\text{Beta}}(0,0)\)` prior essentially implies you have truly no knowledge whatsoever about the parameter `\(\theta\)` (even **less** than 0 successes in 0 trials!)

--


- **BUT**: this is an **improper** prior, because it does not integrate/sum to 1 (which is a fundamental property of probability distributions)

`$$\theta \sim\style{font-family:inherit;}{\text{Beta}}(0,0) \Rightarrow \int_0^1 p(\theta\mid\alpha=0,\beta=0)d\theta \propto \int_0^1 \frac{1}{\theta(1-\theta)}d\theta \rightarrow \infty$$`

- It is possible that when using improper priors, the posterior also does not integrate to 1, which means you **cannot** make probabilistic assessment of your output &amp;ndash; in that case, Bayesian inference is not valid 

--


- It is still OK to consider this intuition and set up to validate the idea that a Beta prior can be formed to encode a thought experiment with `\(y_0\)` "successes" out of `\(n_0\)` "trials"

---

# Example: Drug

## Recap from last lecture

- Consider a drug to be given for relief of chronic pain


- Experience with similar compounds has suggested that annual response rates between 0.2 and 0.6 could be feasible


- Interpret this as a distribution with mean = 0.4, standard deviation 0.1


- `\(\rightarrow\)` Beta(9.2,13.8) **prior** distribution 

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

We actually do the study and **observe** 15 successes out of 20 patients

- Predict whether `\(&gt;\)` 25 successes in next 40 patients

---

# Example: Drug 
### Prior distribution


&lt;img src="./img/unnamed-chunk-7-1.png" style="display: block; margin: auto;" width="40%" title="Once again, this graph shows the Beta with parameters a=9.2 and b=13.8, encoding the assumption that the prior average for the probability of success for the drug is about 40%, with 95% interval between 20 and 60%"&gt;

Beta(9.2, 13.8) prior distribution supporting response rates between 0.2 and 0.6

---

count: false
# Example: Drug 
### Likelihood


&lt;img src="./img/unnamed-chunk-9-1.png" style="display: block; margin: auto;" width="40%" title="This is the likelihood function (proportional to the sampling distribution) and describes the contribution produced by the observed data"&gt;
Likelihood arising from a Binomial observation of 15 responders out of 20 patients given the drug
`\(\displaystyle\mathcal{L}(\theta) = \theta^{15}(1-\theta)^{(20-15)} \Rightarrow \style{font-family:inherit;}{\text{MLE = 15/20}} =\)` 0.75

---

count: false
# Example: Drug 
### Posterior distribution


&lt;img src="./img/unnamed-chunk-11-1.png" style="display: block; margin: auto;" width="40%" title="The posterior can be fully described by combining the values of the prior parameters a and b with the summary statistics (the observed number of successes y and the observed sample size n. This is an example of conjugate analysis"&gt;
Parameters of the Beta distribution are updated to `\(\displaystyle (a+15, b+20-15) = (24.2, 18.8)\)`: **posterior mean**: 24.2/(24.2+18.8) = 0.56.

---

# Conjugate distributions

This is a case of **conjugate analysis**, when the posterior distribution is in the same **family** as the prior distribution

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
Other examples:

- Gamma prior for **rate** parameter of a Poisson likelihood (for count data, e.g. number of people arriving at emergency department)

- Normal prior for mean of a Normal likelihood

- Gamma prior for precision (1/variance) of a Normal likelihood

&lt;span style="display:block; margin-top: 2rem ;"&gt;&lt;/span&gt;
Advantage: don't need simulation to determine posterior

... But real situations usually more complex `\(\Rightarrow\)` software like `BUGS` needed

---

&lt;style type="text/css"&gt;
/* No background */
.remark-slide tr:nth-child(even) {
  background: #FFFFFF; /*#e2e2f9*/
}
.remark-slide tr:nth-child(odd) {
  background: #FFFFFF; /*#e2e2f9*/
}
/* No borders */
.remark-slide table {
  margin: auto;
  border-top: 0px solid #666;
  border-bottom: 0px solid #666;
}
&lt;/style&gt;

# Drug (continued)

### Learning from data using  Markov chain Monte-Carlo (MCMC) methods

Assume we observed 15 successes out of 20 subjects, and wish to predict whether we will get `\(&gt;\)` 25 successes in next 40 patients

The model can be written  
&lt;table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;"&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #035AA6 !important;"&gt; \(\theta\sim\style{font-family:inherit;}{\text{Beta}}(a,b)\) &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; prior distribution &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #035AA6 !important;"&gt; \(y\sim\style{font-family:inherit;}{\text{Binomial}}(\theta,m)\) &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; sampling distribution &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #035AA6 !important;"&gt; \(y_{\rm pred} \sim\style{font-family:inherit;}{\text{Binomial}}(\theta,n)\) &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; predictive distribution &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #035AA6 !important;"&gt; \(P_{\rm crit}=\Pr(y_{\rm pred}\ge n_{\rm crit})\) &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; probability of exceeding critical threshold &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


```r
model {
  theta ~ dbeta(a, b)                     # prior distribution
  y ~ dbin(theta, m)                      # sampling distribution
  y.pred ~ dbin(theta, n)                 # predictive distribution
  P.crit &lt;- step(y.pred - n.crit + 0.5)   # =1 if y.pred &gt;= ncrit
                                          # =0 otherwise
}
```

---

# Graphical model

## (Equivalent to BUGS code)

&lt;center&gt;&lt;img src=./img/BUGS_model.png width='600px' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;

- "Parent" nodes (start of arrow) generate "child" nodes (end of arrow)    
   - data `y` generated by model with parameter `theta`
   - parameter `theta` generated by its "parents" `a,b`
- `BUGS` samples from **posterior** of `theta` &amp;ndash; formed by combining data `y` (**likelihood**) and **prior** parameters `a,b`    
- Evidence flows **up and down** arrows: Knowing about  child `y` tells you about parent `theta`, just as information on `theta` used to predict child `y.pred`

---

# MCMC (Markov chain Monte Carlo)

## Gibbs sampling

- Uses a **Markov chain** (type of random walk &amp;ndash; distribution for the next simulated value depends only on current value)

- Give **initial values** to parameters `\(\theta_1,\ldots,\theta_P\)`

- **Update** parameter values by repeatedly sampling from **full-conditional** posterior distribution of

`$$(\theta_1 \mid  \style{font-family:inherit;}{\text{ current }}\, \theta_p: p \neq 1)$$`
`$$(\theta_2 \mid  \style{font-family:inherit;}{\text{ current }}\, \theta_p: p \neq 2)$$`
`$$\ldots$$`
`$$(\theta_P \mid  \style{font-family:inherit;}{\text{ current }}\, \theta_p: p \neq P)$$`

&amp;emsp; then repeat the cycle until **convergence** (more on this later!)

- Should converge to sampling from **joint posterior** of all unknown quantities `\(\theta_p\)` of interest

- Summarize marginal posterior of `\(\theta_p\)` using converged sample:
   - Use sample mean as estimate of posterior mean
   - Draw smoothed **histogram** to estimate shape of posterior

---

count: false
# MCMC (Markov chain Monte Carlo) 

## Gibbs sampling

**(Convenient) Example: semi-conjugated Normal model**

Assume    
- `\(\displaystyle y_i \stackrel{iid}{\sim} \style{font-family:inherit;}{\text{Normal}}(\mu,\sigma^2), \qquad\)` with `\(i=1,\ldots,n\Rightarrow\)` observed data    
- `\(\displaystyle \mu \mid \sigma^2 \sim \style{font-family:inherit;}{\text{Normal}}(\mu_0,\sigma^2_0) \qquad \left(\style{font-family:inherit;}{\text{e.g. }} \sigma^2_0=\frac{\sigma^2}{\kappa}\right)\qquad \style{font-family:inherit;}{\text{ and }} \qquad\tau=\frac{1}{\sigma^2} \sim \style{font-family:inherit;}{\text{Gamma}}(\alpha_0,\beta_0)\)`    
for fixed `\(\mu_0,\sigma^2_0, \alpha_0, \beta_0\)`

This implies that:
- **Conditionally on** `\(\sigma^2\)`, `\(\mu\)` has a **conjugate prior** (Normal)
- **Marginally**, `\(\tau\)` has a **conjugate prior** (Gamma)    

--

Can prove that under these assumptions 
&lt;span style="display:block; margin-top: -40px ;"&gt;&lt;/span&gt;
`$$\displaystyle\mu\mid\sigma^2,\boldsymbol{y} \sim \style{font-family:inherit;}{\text{Normal}}(\mu_1,\sigma^2_1) \qquad \style{font-family:inherit;}{\text{with: }} \,\mu_1=\sigma^2_1\left(\frac{\mu_0}{\sigma^2_0}+\frac{n\bar{y}}{\sigma^2}\right) \quad \style{font-family:inherit;}{\text{ and }} \quad \sigma^2_1=\left(\frac{1}{\sigma^2_0}+\frac{n}{\sigma^2}\right)^{-1}$$` 
`$$\displaystyle\tau\mid\mu,\boldsymbol{y} \sim \style{font-family:inherit;}{\text{Gamma}}(\alpha_1,\beta_1) \qquad \style{font-family:inherit;}{\text{with: }}\,\alpha_1=\alpha_0+\frac{n}{2}\quad \style{font-family:inherit;}{\text{ and }} \quad \beta_1 = \beta_0 + \frac{1}{2}\sum_{i=1}^n (y_i-\mu)^2$$`

---

name: mcmc0
# MCMC 
### Gibbs sampling &amp;ndash; convergence




&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

&lt;center&gt;&lt;img src=./img/unnamed-chunk-16-1.png width='55%' title='This graph shows the true joint posterior for the mean and the sd and the starting point (initialisation). In reality, we do not know the true posterior and we want to sample using the MCMC algorithm to approximate it'&gt;&lt;/center&gt;
---

count: false
# MCMC 
### Gibbs sampling &amp;ndash; convergence



&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

&lt;center&gt;&lt;img src=./img/unnamed-chunk-17-1.png width='55%' title='Then we first simulate from the posterior of the mean given the current value of the sd (we know what this distribution is because of semi-conjugacy) and we move along the x-axis to the new value. Then we simulate from the posterior of the sd given this new value for the mean and make the move to the new point'&gt;&lt;/center&gt;

---

count: false
# MCMC 
### Gibbs sampling &amp;ndash; convergence



&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

&lt;center&gt;&lt;img src=./img/unnamed-chunk-18-1.png width='55.5%' title='We repeat the process and move first along the x-axis and then along the y-axis to reach the new point'&gt;&lt;/center&gt;

---

count: false
# MCMC 
### Gibbs sampling &amp;ndash; convergence



&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

&lt;center&gt;&lt;img src=./img/unnamed-chunk-19-1.png width='55%' title='... and we continue to repeat - the graph shows the situation after 10 iterations'&gt;&lt;/center&gt;

---

count: false
# MCMC 
### Gibbs sampling &amp;ndash; convergence



&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

&lt;center&gt;&lt;img src=./img/unnamed-chunk-20-1.png width='55%' title='... and after 30 iterations. In this case, we can see that we are indeed covering a lot of the target distribution'&gt;&lt;/center&gt;

---

count: false
# MCMC 
### Gibbs sampling &amp;ndash; convergence



&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

&lt;center&gt;&lt;img src=./img/unnamed-chunk-21-1.png width='55%' title='... After 500 iterations, we've completely covered the target portion of the parametric space, although we started off from a very distant point (marked as 0)'&gt;&lt;/center&gt;

---

count: false
# MCMC 
### Gibbs sampling &amp;ndash; convergence

&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

&lt;center&gt;&lt;img src=./img/convergence.png width='600px' title='To assess convergence, we can start 2 independent chains from very difference points. If the process works, after a while they will go on top of each other, meaning that both are visiting the same part of the parametric space (the target distribution'&gt;&lt;/center&gt;

---

count: false
exclude: true
# MCMC 
### Gibbs sampling &amp;ndash; convergence

&lt;center&gt;&lt;img src=./img/iter1_1.png width='58%' title=''&gt;&lt;/center&gt;
---

count: false
exclude: true
# MCMC 
### Gibbs sampling &amp;ndash; convergence

&lt;center&gt;&lt;img src=./img/iter1_2.png width='58%' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;
---

count: false
exclude: true
# MCMC .subtitle[Gibbs sampling &amp;ndash; convergence]

&lt;center&gt;&lt;img src=./img/iter1_3.png width='58%' title=''&gt;&lt;/center&gt;

---

count: false
exclude: true
# MCMC .subtitle[Gibbs sampling &amp;ndash; convergence]

&lt;center&gt;&lt;img src=./img/iter1_4.png width='58%' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;

---

name: caterpillar
# Checking convergence: monitoring samples

.pull-left[
&lt;center&gt;&lt;img src=./img/trace_all_draft.jpg width='380px' title='These are examples of traceplots for hypothetical analyses. We would like to see a 'fat hairy caterpillar' indicating convergence'&gt;&lt;/center&gt;
]
.pull-right[

- Convergence (or lack of) can be apparent from one chain
   - Want **fat hairy caterpillars** (b) &amp;ndash; not twisting  snakes

- Chain may have converged but be slow to **mix** (c)
   - Run chain for longer (d) to get more precise estimates

- One chain may get "stuck" in some area due to extreme initial value (a)
   - Run multiple chains from different initial values (e): check all end up in same place

- Parameterisation may make a big difference (see manual)
]

---

# Formal convergence tests

Formal diagnostics exist to check if multiple chains end up in essentially same place, eg Brooks-Gelman-Rubin (often referred to as Potential Scale Reduction, PSR) statistic

&lt;span style="display:block; margin-top: 3rem ;"&gt;&lt;/span&gt;

.pull-left[
&lt;center&gt;&lt;img src=./img/bgr.jpg width='500px' title='The PSR statistic shows the ratio of the within to between chain variation. When these two things are similar, it means that the chains are varying more or less at the same rate and over the same part of the parametric space, to indicate convergence'&gt;&lt;/center&gt;
]

.pull-right[

- Based on ratio of between to within variances of multiple chains: (ANOVA)

- `OpenBUGS` produces plots of
   - Average 80% interval within-chains (blue) and pooled 80% interval between-chains (green)
   - Ratio green/blue should converge to 1 (red) as iterations increase

]

&lt;span style="display:block; margin-top: 1em ;"&gt;&lt;/span&gt;

- `coda` and `R2OpenBUGS` packages for `R` contain many other diagnostics    
- **NB** This is only a heuristic measure &amp;ndash; more recent work suggests alternative ways    
   - [https://avehtari.github.io/rhat_ess/rhat_ess.html](https://avehtari.github.io/rhat_ess/rhat_ess.html)      
   - [http://cknudson.com/Presentations/BayesComp2020.pdf](http://cknudson.com/Presentations/BayesComp2020.pdf)

---

# How many iterations after convergence?

- How many significant figures do you need in your estimates: **your decision**

- Easiest strategy: run chains until the posterior summaries of interest don't change

- Monte Carlo Standard Error (MCSE) says how accurate the posterior mean is

- **Autocorrelated** samples need to be longer to get the same accuracy, compared to independent samples
   - Some theory (Raftery &amp; Lewis, see `BUGS` Book for further details) suggests that to get 95% posterior quantiles with true 94.5-95.5% coverage need MCSE/posterior SD &lt; 0.01, or **effective sample size** &gt; 4000

---

# Supplying data to `BUGS`


1. Rectangular format &amp;ndash; traditional "spreadsheet"-shaped data

```r
n[] r[]
 47  0
148 18
...
360 24
END
```


&lt;ol style="counter-reset: my-awesome-counter 1;"&gt;
&lt;li&gt;&lt;span style="font-family:Inconsolata;"&gt;R&lt;/span&gt; / &lt;span style="font-family:Inconsolata;"&gt;S-Plus&lt;/span&gt; style "lists"&lt;/li&gt;&lt;/ol&gt;

```r
list(N=12,n = c(47,148,119,810,211,196,
          148,215,207,97,256,360),
     r = c(0,18,8,46,8,13,9,31,14,8,29,24))
```


List format more flexible, can specify constants alongside data &amp;ndash; useful for complex multilevel models with variables of different lengths

(**NB** If using `R` interfaces to `BUGS`, just supply data in `R` list object &amp;ndash; see later...)

---

# Supplying data to `BUGS`

## Drugs example

Data can be written after the model description, or held in a separate `.txt` or `.odc` file

```r
list(
  a=9.2, b=13.8,    # prior parameters
  y=15,             # number of successes 
  m=20,             # number of trials
  n=40,             # future number of trials
  ncrit=25          # critical value of future successes
)
```

Alternatively, put all data and constants into model description: 

```r
model{
  theta ~ dbeta(9.2, 13.8)      # prior distribution
  y ~ dbin(theta, 20)           # sampling distribution
  y.pred ~ dbin(theta, 40)      # predictive distribution
  P.crit &lt;- step(y.pred - 24.5) # =1 if y.pred &gt;= ncrit,
                                # =0 otherwise
  y &lt;- 15                       # observed successes
}
```

---

# Initial values

- `BUGS` simulates from posterior &amp;ndash; combination of prior and evidence from data &amp;ndash;  by MCMC

- Posterior **unknown** to start with &amp;ndash; need to **initialize** simulation

- `BUGS` can automatically generate initial values for the simulation using `gen.inits` &amp;ndash; simulates from the prior
   - We have seen this in the practical for forward sampling

- Fine if have informative prior information

- If have fairly "vague" priors, better to provide reasonable values in an initial-values list

Initial values list can be after model description or in a separate file

```r
list(theta=0.1)
```

---

# `OpenBUGS` output and exact answers


```r
node       mean     sd     MC error   2.5%   median   97.5%  start sample
theta     0.5633  0.07458  4.292E-4   0.4139  0.5647  0.7051  1001 30000
y.pred   22.52    4.278    0.02356   14.0    23.0    31.0     1001 30000
P.crit    0.3273  0.4692   0.002631   0.0     0.0     1.0     1001 30000
```

Exact answers from conjugate analysis:

- `\(\theta\)`:  mean 0.563 and standard deviation  0.075

- `\(Y^{\rm pred}\)`:  mean 22.51 and standard deviation  4.31

- Probability of at least 25:  0.329

MCMC results are within Monte Carlo error of the true values

.small[.alignright[&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M256 8c137 0 248 111 248 248S393 504 256 504 8 393 8 256 119 8 256 8zm-28.9 143.6l75.5 72.4H120c-13.3 0-24 10.7-24 24v16c0 13.3 10.7 24 24 24h182.6l-75.5 72.4c-9.7 9.3-9.9 24.8-.4 34.3l11 10.9c9.4 9.4 24.6 9.4 33.9 0L404.3 273c9.4-9.4 9.4-24.6 0-33.9L271.6 106.3c-9.4-9.4-24.6-9.4-33.9 0l-11 10.9c-9.5 9.6-9.3 25.1.4 34.4z"&gt;&lt;/path&gt;&lt;/svg&gt; [Next lecture](../04_Intro_HE/index.html)]]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<style>
.logo {
  background-image: url("../assets/ucl-stats/UCL-stats.png");
  background-size: 14% 7%;
  background-repeat: no-repeat;
  position: absolute;
  top:  2.625%; /* 2.65%em */
  left: 85%;
  width: 100%;
  height: 100%;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // add additional classes to exclude here, e.g.
    // ':not(.inverse)' +
    ':not(.hide-logo)' +
    ':not(.thankyou-michelle)' +
    ':not(.thankyou-barney)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>


<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
